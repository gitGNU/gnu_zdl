#!/bin/bash -i
#
# ZigzagDownLoader (ZDL)
# 
# This program is free software: you can redistribute it and/or modify it 
# under the terms of the GNU General Public License as published 
# by the Free Software Foundation; either version 3 of the License, 
# or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, 
# but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY 
# or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License 
# along with this program. If not, see http://www.gnu.org/licenses/. 
# 
# Copyright (C) 2012
# Free Software Foundation, Inc.
# 
# For information or to collaborate on the project:
# https://savannah.nongnu.org/projects/zdl
# 
# Gianluca Zoni
# http://inventati.org/zoninoz
# zoninoz@inventati.org
#


function usage {
	print_c 3 "Uso (l'ordine degli argomenti non è importante): `basename $0` [wget|axel] [file_in] [-m|--multi] [-h|--help] [-c|--configure] [-u|--update] [-clean] [-i|--interactive]"
	echo
	echo -e "$PROG è abilitato per il download da nowdownload, mediafire.com, uploaded.to (ul.to), easybytez.net

$PROG può essere avviato in due modi:

	1) Generando automaticamente un file per la lista dei link per il download (si chiamerà links.txt)
		- apri un terminale ed entra nella directory che dovrà contenere i file scaricati
		- digita il seguente comando e premi invio: $prog 
		- copia i link dei file da scaricare e incollali nel terminale (vai a capo dopo ogni link)
		- premi la chiocciolina \"@\"
		
	2) Utilizzando un file preparato con un editor di testi (andare a capo dopo ogni link)
		- apri un terminale ed entra nella directory che dovrà contenere i file scaricati
		- digita il seguente comando e premi invio: $prog file_in.txt
		

Per i servizi di sharing seguenti è consigliato l'uso della funzione \"multi\" (aggiungere l'argomento -m alle istruzioni sopra elencate) per procedere con il download in parallelo attraverso l'uso di proxy:
uploaded.to (ul.to), easybytez.net

In caso di interruzione del download (per esempio a causa di disconnessione), i file scaricati attraverso Axel possono riprendere il download dal punto di interruzione (solo se nella cartella che contiene il file scaricato è ancora presente anche un file omonimo con estensione \".st\"). $PROG provvederà automaticamente a recuperare il download o a rieseguirlo da capo. Nel caso in cui anche $PROG è stato terminato, il recupero manuale è possibile riavviando $PROG nella seguente forma:
	$prog file_in [-m] [axel|wget]

file_in sta per il nome del file di testo che contiene i link dei file da scaricare. Se il primo download è stato effettuato nel primo modo (vedi sopra, punto 1: generando automaticamente un file per la lista dei link) allora file_in è links.txt. Gli argomenti \"-m\" e \"axel\" (o \"wget\")  sono facoltativi.

Se i file interrotti sono stati scaricati con Wget, non possono essere recuperati e verranno cancellati dalla directory prima di effettuare il riavvio di $PROG. I servizi di file-sharing seguenti sono abilitati solo per il download con Wget: uploaded.to (ul.to), easybytez.net. Gli altri servizi (nowdownload, mediafire.com) sono abilitati di default per Axel e se interrotti possono essere recuperati e completati (automaticamente da $PROG o manualmente riavviando $PROG nella modalità suggerita qui sopra).

L'argomento [wget|axel], wget oppure axel, consente la scelta del downloader. Axel è un acceleratore di download fortemente consigliato e abilitato di default ma disabilitato per alcuni servizi si filesharing. L'argomento [-c|--configure] consente di configurare il downloader di default, cioè di selezionare Wget al posto di Axel senza dover attivare Wget manualmente adottando l'argomento \"wget\".

L'argomento [-clean] cancella eventuali residui di file temporanei di $PROG nella directory di destinazione, prima di iniziare a processare i link immessi dall'utente.

La funzione [-i|--interactive] permette di visualizzare i download \"vivi\" di $PROG anche da un altro terminale oppure nel caso in cui $PROG è terminato (per vostra volontà, premendo Ctrl+C, oppure accidentalmente). Infatti, i download procedono in background e non muoiono insieme a $PROG (tecnicamente possono essere tutti uccisi \"terminando il terminale\"). Per uccidere (definitivamente oppure per riavviarli automaticamente) uno o più processi già avviati, anche con $PROG perfettamente attivo, da un altro terminale entrare nella directory di destinazione e digitare \"$prog -i\" o \"$prog --interactive\": comparirà un'interfaccia (per ora molto rudimentale) con cui poter interagire con i processi di $PROG.

È possibile (ed è raccomandato) far processare, nella stessa lista, link di mirror diversi per uno stesso file (per esempio: vogliamo scaricare file.part1.rar, file.part2.rar e file.part3.rar e abbiamo copie di questi file in uploaded e in easybytez. Si consiglia di usare tutti i link disponili, sia quelli di easybytez che quelli di uploaded: $PROG processerà tutti i link e scaricherà una sola copia dei file, utilizzando il link migliore).

Per aggiornare $PROG è sufficiente usare l'argomento -u (--update).

$PROG funziona anche su Windows. 
Installazione su Windows in due fasi:
	FASE 1 _ Installazione di Cygwin
		- installatore automatico di Cygwin (serve anche ad aggiornare il sistema emulato e ad installare nuovi pacchetti): http://cygwin.com/setup.exe
		- installare il pacchetto \"wget\"

	FASE 2 _ Installazione di $PROG e di Axel
		- salvare nella cartella C:\\\cygwin il seguente file: http://inventati.org/zoninoz/html/upload/files/install_zdl-cygwin.sh
		- avviare cygwin installato nella fase 1 
		- digitare il seguente comando: /install_zdl-cygwin.sh

Uso di $PROG su Windows: avviare cygwin e utilizzare $PROG nel terminale avviato, come descritto in questa guida.

$PROG è rilasciato con licenza GPL (General Public Licence, v.3 e superiori).

Per informazioni e per collaborare al progetto:
https://savannah.nongnu.org/projects/zdl

Gianluca Zoni (zoninoz)
http://inventati.org/zoninoz
"	
	echo
	echo
	exit 1
}


function init {
	log=0
	n=32
	[ -e "/cygdrive" ] && n=10
	multi=0
	prog=`basename $0`
	PROG=`echo $prog | tr a-z A-Z`
	path_tmp=".${prog}_tmp"
	file_log="${prog}_log.txt"
	conf="$HOME/.${prog}rc"
	file_data="$HOME/.${prog}.data"
	uploaded=0
	
	url_update="http://inventati.org/zoninoz/html/upload/files/zdl"
	max_waiting=40
	mkdir -p "$path_tmp"
	
	#user_agent="Mozilla/5.0 (X11; Linux x86_64; rv:10.0.5) Gecko/20100101 Firefox/10.0.5 Iceweasel/10.0.5"
	
	pid_prog=`ps |grep "$prog" |awk '{ print($1) }'|sed -n "1p"`
	pid_in=1   #$pid_prog
	
	rm -f $path_tmp/links_loop.txt
	
	if [ -f "$conf" ]; then
		downloader_in=`cat $conf`
	else
		downloader_in=Axel
	fi
}

#### layout

function print_c {
  case "$1" in
    1)
       echo -n -e '\e[1;32m' #verde
    ;;
    2)
       echo -n -e '\e[0;33m' #giallo
    ;;	
    3)
       echo -n -e '\e[1;31m' #rosso
    ;;	
  esac
  echo -n $2
  echo -e '\e[0m'
}

function separator {
	#COLUMNS=$( tput cols ) 2>/dev/null
	if [ ! -z "$COLUMNS" ];then
		for column in `seq 1 $COLUMNS`; do echo -n -e "\e[1;34m"$1'\e[0m' ; done
	fi
}

function header {
	echo -n -e "\e[1;34m"ZigzagDownLoader [$PROG]"\e[0m\n"
}



function _log {
	if [ $log == 0 ]; then
		echo -e "I file seguenti non sono stati scaricati perchè già presenti nella directory di destinazione o perché non disponibili (forse solo temporaneamente):\n">$file_log
		log=1
	fi
	date >> $file_log
	
	case $1 in
		1)
			echo
			print_c 3  "File $file_in già presente nella directory di destinazione"  | tee -a $file_log
			echo
			;;
		2)
			echo
			if [ ! -z "$link" ]; then
				link_log=" (link di download: $link) "
			fi
			print_c 3  "$url_in --> File ${file_in}${link_log}non disponibile, riprovo più tardi"  | tee -a $file_log
			echo
			links_loop + "$url_in"
			;;
		3)
			echo
			print_c 3  "$url_in --> Indirizzo errato o file non disponibile" | tee -a $file_log
			echo
			;;
		4)
			echo
			print_c 3 "Il file $file_in supera la dimensione consentita dal server per il download gratuito (link: $url_in)" | tee -a $file_log
			echo
			;;
		5)
			echo
			print_c 3 "Nessun nome per il file collegato dal seguente link: $link (connessione interrotta: riprovo più tardi)" | tee -a $file_log
			echo
			;;
		6)
			echo
			print_c 3 "$url_in --> File $file_in troppo grande per lo spazio libero in $PWD su $dev: non sarà scaricato." | tee -a $file_log
			echo
			;;
	esac
	
}



#### change IP address

function check_ip {
	if [ "${newip[*]}" != "${newip[*]//$1}" ]; then 
		if [ ! -f "$file_data" ]; then
			new_ip
		else
			[ "$multi" == "1" ] && new_ip
			[ "$multi" == "0" ] && new_ip_router
		fi
	fi
}

function my_ip {
	myip=`wget -q -O - -t 1 -T 20 checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'`
}

function new_ip_router {
	if [ -f "$file_data" ]; then
		USER=`cat $file_data |awk '{ print($1) }'`
		PASSWD=`cat $file_data |awk '{ print($2) }'`
		print_c 1 "Cambio indirizzo IP..."
		wget --http-passwd=$PASSWD --http-user=$USER 192.168.0.1/stanet.stm  -O - &>/dev/null
		wget --http-passwd=$PASSWD --http-user=$USER --post-data="disconnect=1" 192.168.0.1/cgi-bin/statusprocess.exe -O - &>/dev/null
	else
		echo
		print_c 3 "Funzione di cambio indirizzo IP via router disattivata: non esiste il file di configurazione $HOME/.${prog}.data"
	fi
}

function noproxy {
		unset http_proxy
		export http_proxy
}

function new_ip {
	maxspeed=0
	minspeed=25
	unset close unreached speed
	rm -f "$path_tmp/proxy.tmp"
	#proxy_types=( "Transparent" "Anonymous" "Elite" )
	while true; do
		proxy=""
		#### tipi di proxy: Anonymous Transparent Elite
		proxy_types=( "Transparent" )
		#[ "$domain" != "${domain//mediafire.}" ] && proxy_types=( "Elite" )
		[ "$domain" != "${domain//uploaded.}" ] && proxy_types=( "Anonymous" "Elite" )
		#[ "$domain" != "${domain//shareflare.}" ] && proxy_types=( "Transparent" )
		#[ "$domain" != "${domain//easybytez.}" ] && proxy_types=( "Transparent" )
		ptypes="${proxy_types[*]}"
		print_c 1 "Aggiorna proxy (${ptypes// /, }):"
		old=$http_proxy
		
		noproxy
		line=1
		while [ -z "$proxy" ] ; do		
			#rm -f "$path_tmp/proxy.tmp"
			if [ ! -f "$path_tmp/proxy.tmp" ]; then
				wget -q -t 1 -T 20 --user-agent="Anonimo" http://www.ip-adress.com/proxy_list/ -O "$path_tmp/proxy.tmp" &>/dev/null
				rm -f "$path_tmp/proxy2.tmp"
			fi
			
			for proxy_type in ${proxy_types[*]}; do
				less "$path_tmp/proxy.tmp"|grep "Proxy_Details" |grep "${proxy_type}" >> "$path_tmp/proxy2.tmp"
			done
			
			max=`wc -l "$path_tmp/proxy2.tmp" | awk '{ print($1) }'`
			#cat "$path_tmp/proxy2.tmp"
			string_line=`cat "$path_tmp/proxy2.tmp" |sed -n "${line}p"`
			
			proxy="${string_line#*Proxy_Details\/}"
			[ "$proxy" != "${proxy%:Anonymous*}" ] && proxy_type="Anonymous"
			[ "$proxy" != "${proxy%:Transparent*}" ] && proxy_type="Transparent"
			[ "$proxy" != "${proxy%:Elite*}" ] && proxy_type="Elite"
			proxy="${proxy%:${proxy_type}*}"
			
			z=$(( ${#proxy_done[*]}-1 ))
			if (( $z<0 )) || [ "$z" == "" ]; then z=0 ; fi
			
			for p in `seq 0 $z`; do
				if [ "${proxy_done[$p]}" == "$proxy" ]; then
					proxy=""
				fi
			done
			
			if [ "$string_line" == "" ]; then
					echo -n -e "."
					sleep 3
					(( search_proxy++ ))
					[ $search_proxy == 100 ] && print_c 3 "Finora nessun proxy disponibile: tentativo con proxy disattivato" && noproxy && close=true && break
			fi
			if [ $line == $max ] || [ "$string_line" == "" ]; then
				rm -f "$path_tmp/proxy.tmp"
				line=0
			fi
			(( line++ ))
			[ "$proxy" != "" ] && [ "${proxy_done[*]}" == "${proxy_done[*]//$proxy}" ] && proxy_done[${#proxy_done[*]}]="$proxy"
		done
		unset search_proxy
		[ ! -z $close ] && break
		http_proxy=$proxy
		export http_proxy
		echo -n "Proxy: $http_proxy ($proxy_type)"
		echo
		unset myip
		#my_ip
		#echo "Nuovo IP: $myip"
		print_c 2 "Test velocità di download:"
		index=0
		while (( $index<3 )); do
			index=${#speed[*]}
			speed[$index]=`wget -t 1 -T $max_waiting -O /dev/null "$url_in" 2>&1 | grep '/s'`  #'\([0-9.]\+ [KM]B/s\)'`
			speed[$index]="${speed[$index]#*'('}"
			show_speed="${speed[$index]## }"
			show_speed="${show_speed%%)*}"
			if [ "${speed[$index]}" != "${speed[$index]% B/s*}" ]; then
				speed[$index]="0"
			elif [ "${speed[$index]}" != "${speed[$index]//'KB/s'}" ]; then
				speed[$index]="${speed[$index]%%' '*}"
				speed[$index]="${speed[$index]%','*}"
			elif [ "${speed[$index]}" != "${speed[$index]//'MB/s'}" ]; then
				speed[$index]="${speed[$index]%%' '*}"
				speed[$index]="${speed[$index]//,/.}"
				speed[$index]="${speed[$index]%% *}"
				speed[$index]=`echo "${speed[$index]}*1024" | bc -l`
				speed[$index]="${speed[$index]%'.'*}"
			fi
			if [ "${speed[$index]}" == "" ]; then
				#print_c 3 "Download interrotto"
				#unreached="true"
				#break
				speed[$index]=0
				show_speed=`print_c 3 "0 B/s"`
			fi
			
			echo "$show_speed"
		done 2>/dev/null
		
		if [ -z $unreached ]; then
			
			for k in ${speed[*]}; do  
				if (( $maxspeed<$k )); then 
					maxspeed=$k 
				fi 
			done
			
			if (( $maxspeed<$minspeed )); then
				print_c 3 "La massima velocità di download raggiunta usando il proxy è inferiore a quella minima richiesta ($minspeed KB/s)"
				#unset $proxy
				
			else
				print_c 1 "Massima velocità di download raggiunta usando il proxy $http_proxy: $maxspeed KB/s"
				break
			fi 2>/dev/null
		fi
		unset unreached speed
	done
	unset maxspeed
	echo
	rm -f "$path_tmp/proxy.tmp"
	old_proxy="$proxy"
}

#### hacking web pages



function get_tmps {
	while [ "`less $path_tmp/zdl.tmp |grep \</html`" == "" ]; do
		#print_c 2 "\nAttendi..."
		wget -t 5 -T $max_waiting --retry-connrefused --save-cookies=$path_tmp/cookies.zdl -O "$path_tmp/zdl.tmp" $url_in  &>/dev/null
		echo -e "...\c"
	done
}

function input_hidden {
	j=1
	less $tmp | grep input | grep hidden > $path_tmp/data.tmp
	max=`wc -l "$path_tmp/data.tmp" | awk '{ print($1) }'`
	max=$(( $max+1 ))
	
	while [ $j != $max ]; do
		data=`less $path_tmp/data.tmp |sed -n "${j}p"`
		
		name=${data#*name=\"}
		name=${name%%\"*}
		value=${data#*value=\"}
		value=${value%%\"*}
		
		if [ "$name" == "realname" ] || [ "$name" == "fname" ]; then # <--easybytez e sharpfile
			nomefile="$value"
		fi

		if [ "$post_data" == "" ]; then
			post_data="${name}=${value}"
		else
			post_data="${post_data}&${name}=${value}"
		fi
		(( j++ ))
	done
}


function pseudo_captcha {
	j=0
	for cod in ${ascii_dec[*]}; do 
		captcha[$j]=`printf "\x$(printf %x $cod)"`
		(( j++ ))
	done
}



#### Axel

function check_downloader {
	if [ "$downloader_in" == "Axel" ]; then
		while [ -z "`which axel 2>/dev/null`" ]; do
			clear
			print_c 3 "ATTENZIONE: Axel non è installato nel tuo sistema"
			
			echo -e "$PROG può scaricare con Wget ma raccomanda fortemente Axel, perché:\n
		- può accelerare sensibilmente il download
		- permette il recupero dei download in caso di interruzione
		
	Per ulteriori informazioni su Axel: http://alioth.debian.org/projects/axel/
	
	1) Installa automaticamente Axel da pacchetti
	2) Installa automaticamente Axel da sorgenti
	3) Esci da $PROG per installare Axel manualmente (puoi trovarlo qui: http://pkgs.org/search/?keyword=axel)
	4) Ignora Axel e continua con Wget
	5) Configura Wget di default
	6) Ripristina la condizione iniziale (Axel di default)"
	
			print_c 2 "Scegli cosa fare (1-6)"
			read input
			
			case $input in
			
			1) install_pk ;;
			2) install_src ;;
			3) exit ;;
			4) downloader_in=Wget ; break ;;
			5) echo Wget > $conf ;;
			6) rm $conf ;;
			
			esac
		done
	fi
}

function install_test {
	
	if [ -z "`which axel 2>/dev/null`" ]; then
		print_c 3 "Installazione automatica non riuscita"
		case $1 in
			pk) echo "$2 non ha trovato il pacchetto di Axel" ;;
			src) echo "Errori nella compilazione o nell'installazione";;
		esac
	fi
	echo
	print_c 2 "<Premi un tasto per continuare>"
	read
}

function install_pk {
	print_c 1 "Installo Axel ..."
	if [ `which apt-get 2>/dev/null` ]; then
		DEBIAN_FRONTEND=noninteractive sudo apt-get --no-install-recommends -q -y install axel || (  echo "Digita la password di root" ; DEBIAN_FRONTEND=noninteractive su -c "apt-get --no-install-recommends -q -y install axel" )
		install_test pk apt-get
	elif [ `which yum 2>/dev/null` ]; then
		sudo yum install axel || ( echo "Digita la password di root" ; su -c "yum install axel" )
		install_test pk yum
	elif [ `which pacman 2>/dev/null` ]; then
		sudo pacman -S axel 2>/dev/null || ( echo "Digita la password di root" ; su -c "pacman -S axel" )
		install_test pk pacman
	else
		install_test
	fi
}

function install_src {
	cd /usr/src
	wget http://alioth.debian.org/frs/download.php/3015/axel-2.4.tar.gz
	tar zxvf axel-2.4.tar.gz
	cd axel-2.4
	
	make
	sudo make install || ( echo "Digita la password di root" ; su -c "make install" )
	make clean
	install_test src
	cd -
}

function configure {
	echo
	print_c 3 "CONFIGURAZIONE DI $PROG"
	echo "Il downloader attuale di $PROG è $downloader_in"
	echo
	print_c 2 "Scegli il downloader (wget|axel):"
	read dloader
	case $dloader in
		wget) 
			downloader_in=Wget
		;;
		axel) 
			downloader_in=Axel
		;;
		*)
			print_c 3 "Downloader non riconosciuto: puoi scegliere solo wget o axel"
			exit 1
		;;
	esac
	echo $downloader_in > $conf
	echo
	print_c 1 "$PROG scaricherà con $downloader_in"
	exit
}

#### ZDL

function check_freespace {
	if [ -f ${file_in}_stdout.tmp ]; then
		data_stdout $path_tmp/${file_in}_stdout.tmp
		if [ $? == 5 ]; then
			fsize=$(( ${lenght_out[0]}/1024 ))
		else
			fsize=0
		fi
	else
		fsize=0
	fi
	
	mkdir -p $path_tmp
	df > $path_tmp/df.tmp
	
	maxl=`wc -l $path_tmp/df.tmp |awk '{ print($1) }'`
	pattern=`ls -l "$PWD"`
	pattern="${pattern#*-> }"
	for l in `seq 2 $maxl`; do
		dev=`cat $path_tmp/df.tmp | awk '{ print($6) }' | sed -n "${l}p"`
		if [ "$dev" == "/" ]; then dev="/home" ; fi
		freespace=`cat $path_tmp/df.tmp | awk '{ print($4) }' | sed -n "${l}p"`
		
		if [ "$pattern" != "${pattern//$dev}" ]; then
			if (( $freespace<5000 )); then
				print_c 3 "Spazio insufficiente sul device. $PROG terminato."
				exit
			elif [ $fsize != 0 ] && (( $freespace<$fsize )); then
				kill_in
				_log 6
			fi
		fi
	done
	unset fsize
}



function download {
	if [ "$downloader_in" = "Axel" ]; then
		export AXEL_COOKIES=$path_tmp/cookies.zdl
		print_c 1 "downloading --> $file_in ..."
		[ "$file_in" != "" ] && argout="-o"
		# -a tolto
		axel -n $n "$link" $argout "$file_in" >> "$path_tmp/${file_in}_stdout.tmp" & 
		pid_in=$!
		echo -e "${pid_in}\nlink_${prog}: $url_in\nAxel" > "$path_tmp/${file_in}_stdout.tmp"
		pids_alive[${#pids_alive[*]}]=${pid_in}
		unset post_data
		
	elif [ "$downloader_in" = "Wget" ]; then
		print_c 1 "downloading --> $file_in ..."
		[ "$file_in" != "" ] && argout="-O" && fileout="$file_in"
		[ "$domain" != "${domain//easybytez.}" ] && unset argout fileout
		LANG='en_US.UTF-8' wget -t 1 -T $max_waiting --retry-connrefused -c -nc --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl  --post-data="${post_data}" "$link" -S --progress=bar:force $argout "$fileout" -a "$path_tmp/${file_in}_stdout.tmp" & 
		pid_in=$!
		echo -e "${pid_in}\nlink_${prog}: $url_in\nWget" > "$path_tmp/${file_in}_stdout.tmp"
		pids_alive[${#pids_alive[*]}]=${pid_in}
		unset post_data
	fi
}

function check_pid {
	if [ ! -z $1 ]; then
		pid=$1
		ps au | awk '{print $2}' | while read alive; do
			if [ "$alive" == "$pid" ]; then
				return 111
			fi
		done
	fi
}


function show_data_alive {
	data_alive
	if [ ! -z $alive ]; then 
		unset alive

		print_c 1 "Processi di download attualmente in vita:"
		separator "="
		last_alive=$(( ${#pid_alive[*]}-1 ))
		#read -p $last_alive
		for j in `seq 0 $last_alive`; do
			print_c 1 "Numero download attivo: $j"
			[ ! -f "${file_alive[$j]}" ] && print_c 3 "${downloader_alive[$j]} sta scaricando a vuoto: ${file_alive[$j]} non esiste"
			echo -e "File: ${file_alive[$j]}" 
			[ ! -z "${alias_file_alive[$j]}" ] && echo "Alias: ${alias_file_alive[$j]}"
			echo -e "Downloader: ${downloader_alive[$j]}\nLink: ${url_alive[$j]}\nProgresso: ${progress_alive[$j]}"
			if [ $j != $tot ]; then 
				separator "-"
			else
				separator "="
			fi
		done
		return 111
	else
		print_c 1  "Nessun download attivo di $PROG rilevato"
	fi
}

function data_alive {
	data_stdout
	if [ $? == 5 ]; then
		client=1
		tot=$(( ${#pid_out[*]}-1 ))
		j=0
		for i in `seq 0 $tot`; do
			check_pid ${pid_out[$i]}
			if [ $? == 111 ]; then
				pid_alive[$j]="${pid_out[$i]}"
				file_alive[$j]="${file_out[$i]}"
				downloader_alive[$j]="${downloader_out[$i]}"
				alias_file_alive[$j]="${alias_file_out[$i]}"
				url_alive[$j]="${url_out[$i]}"
				progress_alive[$j]="${progress_out[$i]}"
				length_alive[$j]=${length_out[$i]}
				alive=1
				(( j++ ))
				
			fi
		done
	fi
}

function interactive {
	client=1
	show_data_alive
	if [ $? == 111 ]; then
		echo
		print_c 2 "Seleziona i numeri dei download attivi da riavviare o eliminare, separati da spazi (digita Ctrl+C per uscire subito):"
		read input
		inputs=( $input )
		last_alive=$(( ${#pid_alive[*]}-1 ))
		options=`seq 0 $last_alive`
		while [ "$input2" != "e" ] && [ "$input2" != "r" ] && [ "$input2" != "t" ]; do
			print_c 2 "Vuoi che i download selezionati siano terminati definitivamente oppure che siano riavviati automaticamente più tardi?"
			echo
			echo -e "	e) per eliminarli definitivamente (e cancellare il file), digita \"e\"
	r) per riavviarli digita \"r\"
	t) per terminare il programma senza fare niente digita \"t\""
			
			print_c 2 "Scegli cosa fare: [e | r | t]"
			read input2
			
			if [ "$input2" == "e" ] || [ "$input2" == "r" ]; then
				for s in ${inputs[*]}; do
					if [ "${options}" != "${options//$s}" ]; then
						kill ${pid_alive[$s]}
						rm -f "${file_alive[$s]}" "${alias_file_alive[$s]}" "${file_alive[$s]}_stdout.tmp"
					fi
				done
				if [ "$input2" != "e" ]; then
					if [ -f "$path_tmp/links_loop.txt" ]; then
						links=`cat "$path_tmp/links_loop.txt"`
						for lnk in $links; do
							lnk=`cat $path_tmp/links_loop.txt` 
							[ "${url_alive[*]//$lnk}" == "${url_alive[*]}" ] && echo "$lnk" >> $path_tmp/links_loop2.txt
						done
						[ -f $path_tmp/links_loop2.txt ] && mv $path_tmp/links_loop2.txt $path_tmp/links_loop.txt
					fi
				fi
			elif [ "$input2" != "t" ]; then
				print_c 1  "Nessun processo riavviato o eliminato"
				
			fi
		done
	fi
	exit
}


function kill_in {
	#read -p "funzione kill_in"
	kill ${pid_in}
	killed[${#killed[*]}]=${pid_in}
	unset pid_in

}

function data_stdout {
	unset list
	if [ ! -z "$1" ];then # arg=$path_tmp/${file_in}_stdout.tmp
		list="$1"
	else
		list=`ls -1 $path_tmp/*_stdout.tmp 2>/dev/null`
	fi
	if [ ! -z "$list" ]; then
		unset file_stdout file_out alias_file_out url_out downloader_out pid_out progress_out length_out
		i=0
		for item in $list; do
			
			file_stdout=$item
			head -n 50 "$file_stdout" > $path_tmp/head_stdout

			file_out[$i]="${file_stdout//_stdout.tmp}"
			file_out[$i]="${file_out[$i]#$path_tmp/}"
			
			pid_out[$i]=`head -n 1 "$path_tmp/head_stdout"`
						
			url_out[$i]=`cat "$path_tmp/head_stdout"|grep "link_$prog"`
			url_out[$i]="${url_out[$i]#link_${prog}: }"

			downloader_out[$i]=`head -n 3 "$path_tmp/head_stdout" | sed -n '3p'`
	
			if [ "$downloader_out[$i]" == "Wget" ]; then
				if [ "${file_out[$i]}" != "${file_out//alias}" ];then
					alias_file_out[$i]="${file_out[$i]}"
					
					file_out[$i]=`cat "$path_tmp/head_stdout" |grep filename`
					file_out[$i]="${file_out[$i]#*'filename="'}"
					file_out[$i]="${file_out[$i]%'"'*}"
					file_stdout="$path_tmp/${alias_file_out[$i]}_stdout.tmp"
				fi
				#progress_out[$i]=`tail "$file_stdout" | grep `
				cat $path_tmp/head_stdout > "$file_stdout"
				
				length_out[$i]=`cat "$path_tmp/head_stdout" |grep "Length:" |tail -n 1`
				length_out[$i]="${length_out[$i]#*Length: }"
				length_out[$i]="${length_out[$i]%%' '*}"

			elif [ "$downloader_out[$i]" == "Axel" ]; then
				#progress_out[$i]=`tail "$file_stdout" |grep K |grep % |tail -n 1`
				cat $path_tmp/head_stdout > "$file_stdout"
				
				length_out[$i]=`cat "$path_tmp/head_stdout" |grep 'File size'`
				length_out[$i]="${length_out[$i]#*File size: }"
				length_out[$i]="${length_out[$i]%% *}"

			fi
			progress_out[$i]=`tail "$file_stdout" |grep K |grep % |tail -n 1`
			(( i++ ))
		done
		unset i
		return 5
	fi
}

function show_data_stdout {
	data_stdout
	if [ $? == 5 ]; then
		print_c 1 "Downloading..."
		separator "="
		last_stdout=$(( ${#pid_out[*]}-1 ))
		for i in `seq 0 $last_stdout`; do
			length_saved=0
			[ -f "${file_out[$i]}" ] && length_saved=`ls -l "${file_out[$i]}" 2>/dev/null| awk '{ print($5) }'`
			echo -e "File: ${file_out[$i]} - Downloader: ${downloader_out[$i]}\nLink: ${url_out[$i]}"
			progress="${progress_out[$i]}"
			
			check_pid ${pid_out[$i]}
			if [ -z $? ]; then
				progress="Download non attivo"
			fi
			if [ -f "${file_out[$i]}" ] && [ ! -f "${file_out[$i]}.st" ] && [ "$length_saved" == "${length_out[$i]}" ];then
				progress="Download completato"
			fi
			echo "$progress"
			if [ $i != $last_stdout ] && [ "$multi" == "1" ]; then
				separator "-"
			else
				separator "="
			fi
		done
	else
		print_c 3 "Nessun download attivo"
	fi
}

function check_stdout {
	data_stdout
	if [ $? == 5 ]; then
		last_stdout=$(( ${#pid_out[*]}-1 ))
		#read -p "last:$last_stdout ${#pid_out[*]} ${file_out[*]}"
		unset rm_file
		for i in `seq 0 $last_stdout`; do
			
			check_pid ${pid_out[$i]}
			if [ $? == 111 ]; then # ${pid_out[$i]} is alive
				if [ ! -f "${file_out[$i]}" ] && [ ! -f "${alias_file_out[$i]}" ]; then # download > null
					killed[${#killed[*]}]=${pid_out[$i]}
					kill ${pid_out[$i]}
				elif [ "${pid_out[$i]}" != "$pid_in" ] && [ "$real_file_in" == "${file_out[$i]}" ];then
					return 5
				elif [ "${pid_out[$i]}" == "$pid_in" ] && [ "$real_file_in" == "${file_out[$i]}" ] && [ -f "${alias_file_out[$i]}" ] && [ -f "${file_out[$i]}" ];then
					rm_file[${#rm_file[*]}]="${alias_file_out[$i]}"
					kill ${pid_out[$i]}
				fi 
				
				if [ "$multi" == "1" ]; then
					unset file_in
					checked=1
				fi
				links_loop - "${url_out[$i]}"
				pids_alive[${#pids_alive[*]}]=${pid_out[$i]}
			
			else
			
				var_pids="${pids_alive[*]}"
				var_pids="${var_pids//${pid_out[$i]}/-}"
				var_pids="${var_pids//-}"
				pids_alive=( $var_pids )
				
				already_there=`cat "$path_tmp/${file_out[$i]}_stdout.tmp" 2>/dev/null |grep 'already there; not retrieving.'`
				if [ -z "$already_there" ]; then # morto a posteriori = suicida oppure incidentato/completato
				
					unset already_there
					if [ "${killed[*]}" == "${killed[*]//${pid_out[$i]}}" ]; then # incidentato o completato
						length_saved=0
						[ -f "${file_out[$i]}" ] && length_saved=`ls -l "${file_out[$i]}" | awk '{ print($5) }'`
						
						if ( [ "$length_saved" != "${length_out[$i]}" ] && [ ! -z "${length_out[$i]}" ] && (( ${length_out[$i]}>0 )) ) || [ "${length_out[$i]}" == "0" ]; then  #incidentato
							
							if [ "${alias_file_out[$i]}" != "${file_out[$i]}" ] && [ "${alias_file_out[$i]}" != "" ] ; then
								rm_file[${#rm_file[*]}]="$path_tmp/${alias_file_out[$i]}"
							fi	
							
							[ ! -f "${file_out[$i]}.st" ] && rm_file[${#rm_file[*]}]="${file_out[$i]}"
							links_loop + "${url_out[$i]}"
							checked=1
						else #completato
							#rm_file[${#rm_file[*]}]="$file_stdout"
#							unset file_in
							links_loop - "${url_out[$i]}"
							checked=1
						fi
					else #suicida 
						rm_file[${#rm_file[*]}]="${file_out[$i]}"
#						unset file_in
						checked=1
						killed[${#killed[*]}]=${pid_out[$i]}
					fi
				else
					unset already_there
				# morto a priori = completato oppure escluso fin dall'inizio perché il file è presente prima dell'avvio di $PROG ma è sfuggito all'analisi precedente
					#rm_file[${#rm_file[*]}]="$file_stdout"
#						unset file_in
					checked=1
					links_loop - "${url_out[$i]}"
				fi
			fi
			( [ "${length_out[$i]}" == "unspecified" ] || [ "${length_out[$i]}" == 0 ] || [ -z "${length_out[$i]}" ] ) && rm_file[${#rm_file[*]}]="$path_tmp/${file_out[$i]}_stdout.tmp"
		done
		rm_files
		return 11
	else
		checked=1
	fi
}

function rm_files {
	if [ "${#rm_file[*]}" != "0" ] && [ ! -z "${#rm_file[*]}" ]; then
		for i in `seq 0 $(( ${#rm_file[*]}-1 ))`; do
# 			echo
# 			cat $path_tmp/links_loop.txt
# 			echo
# 			read -p "Cancellazione dei seguenti file: ${rm_file[$rmf]}"
			rm -rf "${rm_file[$i]}" 
			unset rm_file[$i]
		done
	fi

}

function check_in {
	if [ -f "$file_in" ]; then
		data_stdout
		if [ $? == 5 ]; then
			last_stdout=$(( ${#pid_out[*]}-1 ))
			#read -p ${#pid_out[*]}
			for i in `seq 0 $last_stdout`; do
				check_pid ${pid_out[$i]}
				if [ $? == 111 ]; then
					if [ "${file_out[$i]}" == "$file_in" ] && [ "${url_out[$i]}" != "$url_in" ]; then
						links_loop + "$url_in"
					fi
				else
					length_saved=0
					length_alias_saved=0
					[ -f "${file_out[$i]}" ] && length_saved=`ls -l "${file_out[$i]}" | awk '{ print($5) }'`
					[ -f "${alias_file_out[$i]}" ] && length_alias_saved=`ls -l "${alias_file_out[$i]}" | awk '{ print($5) }'`
				
					if [ "${length_out[$i]}" == "unspecified" ] || [ "${length_out[$i]}" == 0 ] || [ -z "${length_out[$i]}" ] || ( ( [ "$file_in" == "${file_out[$i]}" ] || [ "$file_in" == "${alias_file_out[$i]}" ] ) && [ ! -z ${length_out[$i]} ] && (( ${length_out[$i]}>$length_saved )) && (( ${length_out[$i]}>$length_alias_saved )) ); then
					
						[ ! -f "${file_in}.st" ] && rm_file[${#rm_file[*]}]="$file_in"
						links_loop - "$url_in"
					fi
					unset length_saved length_alias_saved
				fi
				( [ "${length_out[$i]}" == "unspecified" ] || [ "${length_out[$i]}" == 0 ] || [ -z "${length_out[$i]}" ] ) && rm_file[${#rm_file[*]}]="$path_tmp/${file_out[$i]}_stdout.tmp"
			done
			rm_files
		fi
	fi
}


function links_loop { #usage with op=+|- : links $op $link
	op="$1" #operator
	link="$2" #link
	if [ "$op" == "+" ]; then
		[ ! -z "$link" ] && echo "$link" >> $path_tmp/links_loop.txt
	elif [ "$op" == "-" ]; then
		#togliere url_in da loop
		if [ -f "$path_tmp/links_loop.txt" ]; then
			lnx=`cat $path_tmp/links_loop.txt`
			for lnk in $lnx; do
				[ "${link[*]//$lnk}" == "${link[*]}" ] && echo "$lnk" >> $path_tmp/links_loop2.txt
			done
			[ -f $path_tmp/links_loop2.txt ] && mv $path_tmp/links_loop2.txt $path_tmp/links_loop.txt
			links=`cat $path_tmp/links_loop.txt`
			[ -z "$links" ] && rm $path_tmp/links_loop.txt
		fi
	fi
	
}

function sanitize {
	if [ ! -f "${file_in}.st" ] && [ -f "${file_in}" ] && [ "$downloader_in" = "Axel" ]; then
		_log 1
		no_newip=true
	elif ( [ -f "${file_in}" ] || [ -f "${path_tmp}/${file_in}" ] ) && [ "$downloader_in" = "Wget" ]; then
		no_newip=true
		check_in
		[ -f "${file_in}" ] && _log 1
	elif [ ! -z "$not_available" ]; then
		[ ! -z "$url_in" ] && _log 3
		no_newip=true
	elif [ ! -z "$exceeded" ]; then
		_log 4
		no_newip=true
	elif [ "$link" == "" ] || [ "${file_in}" == "" ]; then
		_log 2
		unset no_newip
		#no_newip=true
		#old_ip
	elif [ "$link" != "${link//{\"err\"/}" ]; then
		_log 2
		unset no_newip
# 	elif [ "${file_in}" == "" ]; then
# 		_log 5
# 		unset no_newip
	elif [ ! -z "$url_in" ]; then
		return 1
	fi
}

init

################################### HEADER
header
separator z
###################################
for arg in $@ ; do
	case "$arg" in
		-i|--interactive)
			interactive
			;;
		-clean)
			( rm -r "$path_tmp"/* 2>/dev/null && print_c 1 "File temporanei cancellati" ) || print_c 3 "Pulizia file temporanei non effettuata (file inesistenti)"
			;;
		-u | --update)
			print_c 1 "Aggiornamento di $PROG ..."
			wget -T $max_waiting "$url_update" -O /tmp/$prog 
			print_c 1 "Installazione di $PROG in /usr/local/bin/"
			( mv /tmp/$prog /usr/local/bin/$prog ; chmod +x /usr/local/bin/$prog ; print_c 1 "Aggiornamento completato." ) || ( sudo mv /tmp/$prog /usr/local/bin/$prog ; sudo chmod +x /usr/local/bin/$prog ; print_c 1 "Aggiornamento completato." ) || ( echo -n "(Root)" ; su -c "mv /tmp/$prog /usr/local/bin/$prog ; chmod +x /usr/local/bin/$prog" ; print_c 1 "Aggiornamento completato." ) || ( print_c 3 "Aggiornamento automatico non riuscito" )
			echo "which ${prog}:"
			which $prog
			echo
			;;
		wget)
			downloader_in=Wget
			;;
		axel)
			downloader_in=Axel
			;;
		
		-m | --multi)
			multi=1
# 			if [ -e "/cygdrive" ]; then
# 				export DISPLAY=:0
# 				X &>/dev/null &
# 				exec aewm++ &>/dev/null &
# 			fi
			;;
		
		-h | --help)
			usage
			;;
			
		-c | --configure)
			configure
			;;
		
		*)
			if [ -f "$arg" ]; then
				file="$arg"
			else
				print_c 3 "Il file $arg non esiste"
				echo
				usage
			fi
			;;
	esac
done

check_downloader

print_c 1 "Download con $downloader_in"


if [ -f "$file_log" ]; then
	log=1
fi

if [ "$file" == "" ] ; then 
	print_c 2 "Incolla la lista dei link (nowdownload, mediafire, uploaded, ul, easybytez) poi digita @" 
	echo "[per uscire da $PROG digita ctrl+c]"
	read -d @ -a links
	printf "%s\n" "${links[@]}" > links.txt
	file="links.txt"
	echo
fi



#converti UL.TO in UPLOADED.TO/FILE
lnks=`cat $file`
rm $file

echo -e "${lnks// /\n}" | while read line ; do 
	if [ "$line" != "${line//http:\/\/ul.to/}" ]; then
		line=${line//ul.to/uploaded.to/file}
		
		
	fi
	echo $line >> $file
done


while true; do
	if [ ! -z "$file" ]; then	
		links_in=`cat $file`
		
		for url_in in $links_in; do
			[ ! -z "$pid_in" ] && check_freespace
			unset pid_in checked file_in
			
			domain=${url_in//\?*}
			echo > $path_tmp/zdl.tmp > $path_tmp/zdl2.tmp
			
			echo
			echo
			separator "Z"
			
			echo -e "\nLink da processare: $url_in"
			
	# 		if [ "$domain" != "${domain//4us.to/}" ]; then
	# 			
	# 			## 4US.TO ###############
	# 			get_tmps		
	# 			link=`cat $path_tmp/zdl.tmp | grep morpheus `
	# 			link=${link#*document.location=\"}
	# 			link=${link%\"*}
	# 			
	# 			file_in=${link##*=} 
	# 			n=1
	# 	
			if [ "$domain" != "${domain//mediafire.}" ]; then
				
				# MEDIAFIRE.COM ##############
				check_ip mediafire
				
				get_tmps
				link=`cat $path_tmp/zdl.tmp |grep 'kNO = '`
				link=${link#*'kNO = "'}
				link=${link//\" onclick=\"avh*/}
				link=${link%'"'*}
				
				file_in=${link##*'/'}
				n=4
			elif [ "$domain" != "${domain//nowdownload.}" ]; then
				
				## http://www.nowdownload ###########
				
				get_tmps
				token=`cat $path_tmp/zdl.tmp | grep token`
				token=${token//*=}
				token=${token//\"*/}
				prelink=${url_in//\/dl/\/dl2}"/$token"
				print_c 2 "Attendi circa 30 secondi:"
				k=`date +"%s"`
				s=0
				unset link
				while true; do

					if (( $s>29 )); then
						wget -t 1 -T $max_waiting --load-cookies=$path_tmp/cookies.zdl -O "$path_tmp/zdl2.tmp" "$prelink" &>/dev/null 
					fi
					sleep 1
					s=`date +"%s"`
					s=$(( $s-$k ))
					
					echo -e $s"\r\c"
					
					link=`cat $path_tmp/zdl2.tmp |grep "Click here to download" 2>/dev/null`
					link=${link//*href=\"} 
					link=${link//\"*}

					[ ! -z "$link" ] && break
				done	
				file_in1=`cat $path_tmp/zdl.tmp | grep 'Downloading'`
				file_in1="${file_in1#*'<br> '}"
				file_in1="${file_in1%%</h4>*}"
				file_in1="${file_in1%' '*}"
				file_in1="${file_in1%' '*}"
				file_in1="${file_in1%' '*}"
				file_in1="${file_in1//'<br>'/}"
				while [ "$file_in1" != "${file_in1%.}" ]; do
					file_in1=${file_in1%.}
				done
				file_in2="${link//*\//}"
				file_in2="${file_in2#*_}"
				
				if [ "$file_in2" != "${file_in2//$file_in1}" ]; then
					file_in="$file_in2"
				else
					file_in="$file_in1"
				fi
	
	# 		elif [ "$domain" != "${domain//sharpfile.}" ]; then
	# 			wget $url_in -O $path_tmp/zdl.tmp &>/dev/null
	# 			tmp="$path_tmp/zdl.tmp"
	# 			input_hidden
	# 			
	# 			if ( [ ! -f "${file_in}.st" ] && [ -f "${file_in}" ] && [ "$downloader_in" = "Axel" ] ) || ( [ -f "${file_in}" ] && [ "$downloader_in" = "Wget" ] ); then
	# 				echo -n
	# 			else
	# 				check_ip sharpfile
	# 				wget --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl $url_in -O $path_tmp/zdl.tmp &>/dev/null
	# 				echo -e "...\c"
	# 				tmp="$path_tmp/zdl.tmp"
	# 				input_hidden
	# 				
	# 				post_data="${post_data//'op=catalogue&'}"
	# 				
	# 				wget --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies2.zdl --post-data="$post_data&method_free=Free Download" $url_in -O $path_tmp/zdl2.tmp &>/dev/null
	# 				
	# 				captcha_html=`cat $path_tmp/zdl2.tmp |grep "position:absolute;padding-left"`
	# 				unset post_data
	# 				unset ascii_dec
	# 				unset i
	# 				while [ ${#ascii_dec[*]} != 4 ];do
	# 					captcha_html="${captcha_html#*'position:absolute;padding-left:'}"
	# 					i="${captcha_html%%px*}"
	# 					captcha_html="${captcha_html#*'&#'}"
	# 					ascii_dec[$i]="${captcha_html%%';'*}"
	# 				done
	# 				pseudo_captcha
	# 				print_c 2 "Attendi:"
	# 				
	# 				code=${captcha[*]}
	# 				code=${code// /}
	# 				
	# 				s=65
	# 				while [ $s != 0 ]; do
	# 					echo -e "  \r\c"
	# 					echo -e $s"\r\c"
	# 					sleep 1
	# 					(( s-- ))
	# 				done
	# 				echo -e "  \r\c"
	# 				tmp="$path_tmp/zdl2.tmp"
	# 				input_hidden
	# 				post_data="${post_data//'op=catalogue&'}"
	# 				post_data="${post_data}&code=${code}"
	# 			fi
	# 			link="$url_in"
	
	# 		elif [ "$domain" != "${domain//shareflare.}" ]; then
	# 			
	# 			## http://www.shareflare.net ####
	# 			check_ip shareflare
	# 			get_tmps
	# 			tmp="$path_tmp/zdl.tmp"
	# 			input_hidden
	# 			if [ ! -f "${file_in}.st" ] && [ -f "${file_in}" ]; then
	# 					echo
	# 			else
	# 				wget --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&submit_ifree=Download file" http://shareflare.net/download4.php -O $path_tmp/download4.tmp &>/dev/null
	# 				echo -e "...\c"
	# 				unset post_data
	# 				
	# 				input_hidden
	# 				wget --load-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&frameset=Download file." http://shareflare.net/download3.php -O $path_tmp/download3.tmp &>/dev/null
	# 				echo -e "...\c"
	# 				
	# 				wget --load-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&frameset=Download file." "http://shareflare.net/tmpl/tmpl_frame_top.php?link=" -O $path_tmp/tmpl_frame_top.php &>/dev/null
	# 				echo -e "...\c"
	# 				
	# 				print_c 2 "Attendi circa 45 secondi:"
	# 				
	# 				k=`date +"%s"`
	# 				while [ "$goal" == "" ]; do
	# 					sleep 1
	# 					s=`date +"%s"`
	# 					s=$(( $s-$k ))
	# 					echo -e $s"\r\c"
	# 					
	# 					if (( $s>40 )); then
	# 						wget --load-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&frameset=Download file." "http://shareflare.net/tmpl/tmpl_frame_top.php?link=" -O $path_tmp/tmpl_frame_top.php &>/dev/null
	# 						
	# 						goal=`less $path_tmp/tmpl_frame_top.php |grep direct_link_0` #grep "========================="`
	# 						sleep 1
	# 					fi
	# 					if (( $s>90 )); then
	# 						break
	# 					fi
	# 				done
	# 				
	# 				link=${goal#*\"}
	# 				link=${link//\"*/}
	# 				
	# 				
	# 				n=1
	# 			fi
	# 			
			elif [ "$domain" != "${domain//easybytez.}" ]; then
				url_in=`wget -t 1 -T $max_waiting -O - $url_in -q |grep 'You have requested'` #&>/dev/null
				url_in="${url_in##*'<font color="red">'}"
				url_in="${url_in%%'</font'*}"
				#url_in="${url_in// /}"
				file_in=${url_in##*\/}
				
				#read -p "$file_in"
				
				not_available=`wget -T $max_waiting -q -O - $url_in |grep "File not available"`
				check_in
				if [ ! -z "${file_in}" ] && [ ! -f "${file_in}" ] && [ -z "$not_available" ]; then
					check_ip easybytez
					
					wget -q -t 1 -T $max_waiting --retry-connrefused --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl -O "$path_tmp/zdl.tmp" $url_in &>/dev/null
					echo -e "...\c"
					
					tmp="$path_tmp/zdl.tmp"
					input_hidden
				
					wget -t 1 -T $max_waiting -q --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl --post-data="${post_data}&method_free=Free Download" $url_in -O $path_tmp/zdl2.tmp &>/dev/null
					echo -e "...\c"
					exceeded=`cat $path_tmp/zdl2.tmp |grep "Upgrade your account to download bigger files"`
					unset post_data
					if [ -z "$not_available" ] && [ -z "$exceeded" ]; then
				
						tmp="$path_tmp/zdl2.tmp"
						input_hidden
		
						wget -t 1 -T $max_waiting -q --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl --post-data="${post_data}&btn_download=Download File" $url_in -O $path_tmp/zdl3.tmp &>/dev/null
						echo -e "...\c"
						unset post_data
					
						print_c 2 "Attendi circa 60 secondi:"
						for s in `seq 0 60`; do
							echo -e $s"\r\c"
							sleep 1
						done
						echo -e "  \r\c"
						tmp="$path_tmp/zdl3.tmp"
						input_hidden
						
						
						link="$url_in"
						post_data="${post_data}&btn_download=Download File"
					fi
					#read -p "$file_in"
				fi
					
			elif [ "$domain" != "${domain//uploaded.}" ]; then
				unset alias
				url_in="${url_in%/}"
				wget -t 1 -T $max_waiting $url_in -q -O $path_tmp/test_page.tmp &>/dev/null
				test_exceeded=`cat $path_tmp/test_page.tmp |grep 'small style'`
				test_exceeded="${test_exceeded#*'>'}"
				test_exceeded="${test_exceeded%'<'*}"
				test_exceeded=`echo $test_exceeded |grep GB`
				if [ ! -z "$test_exceeded" ]; then
					test_exceeded=${test_exceeded%' '*}
					test_exceeded=${test_exceeded//,/.}
					test_exceeded=`echo "( $test_exceeded>1 )" |bc -l 2>/dev/null`
				fi
				#not_available=`cat $path_tmp/test_page.tmp |grep 'Page not found'`
				test_available=`wget -q -O - -t 1 -T $max_waiting $url_in |grep "</html"`
	
				if [ "$test_exceeded" == "1" ]; then
					exceeded=1
				elif [ -z "$test_available" ]; then
					not_available=true
				else
					if [ "${url_in##*/}" != "${url_in//*file\/}" ]; then
						file_in=${url_in##*/}
						url_in2=${url_in%/*}
						file_id=${url_in2##*/}
					else 
						wget -t 1 -T $max_waiting "$url_in" -O $path_tmp/zdl.tmp &>/dev/null
						file_id=${url_in##*/} 
						file_in=`cat $path_tmp/zdl.tmp |grep "id=\"filename\""`
						file_in="${file_in//<\/a*/}"
						file_in="${file_in##*>}"
						if [ "$file_in" != "${file_in//'&alias;'/}" ]; then
							file_in="${file_id}_${file_in//'&alias;'/.}.alias"
							#alias=true
						fi
						
					fi
					check_in
					if [ ! -f "$file_in" ]; then
						check_ip uploaded
						wget -t 1 -T $max_waiting --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl "$url_in" -O $path_tmp/zdl.tmp &>/dev/null
						echo -e "...\c"
						
						cooking=`cat $path_tmp/zdl.tmp |grep ref_user`
						cooking="${cooking//*\(\'/}"
						cooking=${cooking//"'"*/}
						
						echo "uploaded.to     FALSE   /       FALSE   0       ref     $cooking" >> $path_tmp/cookies.zdl
						
						wget -t 1 -T $max_waiting --load-cookies=$path_tmp/cookies.zdl "http://uploaded.to/io/ticket/captcha/$file_id" -O "$path_tmp/goal.tmp" &>/dev/null
						echo -e "...\c"
						
						link=`cat $path_tmp/goal.tmp`
						link=${link//*domain:\'/}
						link=${link//\'*}
					fi
				fi
				
			else
				[ "$domain" != "" ] && print_c 3 "$domain non supportato da $PROG"
				not_available=1
			fi
			file_in="${file_in// /_}"
			
			if [ "$domain" != "${domain//uploaded.}" ] || [ "$domain" != "${domain//easybytez.}" ];then # || [ "$domain" != "${domain//sharpfile.}" ]; then
				if [ "$downloader_in" == "Axel" ]; then
					dler=$downloader_in
					downloader_in=Wget
					ch_dler=1
					print_c 3 "Il server non permette l'uso di $dler: il download verrà effettuato con $downloader_in"
				fi
			fi
			
			#### DOWNLOAD ####
			
			sanitize
			if [ $? == 1 ]; then
				download
				
				if [ $multi == 1 ] && [ "$domain" == "${domain//nowdownload.}" ]; then
					count_down=$(( $max_waiting-10 ))
				else	
					count_down=$(( $max_waiting+5 ))
				fi
				
				print_c 2 "Attendi:"
				while [ "$count_down" != 0 ]; do
					echo -e "  \r\c"
					echo -e $count_down"\r\c"
					sleep 1
					(( count_down-- ))
				done
				echo -e "  \r\c"
				
					
				check_freespace

				# if file_in is an alias
				if [ -f "$file_in" ] && [ -f "$path_tmp/${file_in}_stdout.tmp" ] && [ "$file_in" != "${file_in//.alias}" ]; then
					
					unset real_file_in 
					real_file_in=`cat $path_tmp/${file_in}_stdout.tmp |grep filename`
					real_file_in="${real_file_in#*'filename="'}"
					real_file_in="${real_file_in%'"'*}"
					if [ "$real_file_in" != "" ]; then
						check_stdout
						
						if [ $? == 5 ]; then
							kill_in
							rm -f  "$file_in"
						elif [ ! -f "$real_file_in" ]; then
							mv "$file_in" "$real_file_in"
							print_c 1 "Recupero file_in: $file_in rinominato come $real_file_in"
						fi
						#echo "$pid_prog - file_in:$real_file_in" > "$path_tmp/$file_in"
						unset checked real_file_in
					fi
				fi
				unset no_newip
			fi
			if [ -z $no_newip ]; then
				[ "$domain" != "${domain//mediafire.}" ] && newip[${#newip[*]}]=mediafire
				[ "$domain" != "${domain//uploaded.}" ] && newip[${#newip[*]}]=uploaded
		# 		[ "$domain" != "${domain//shareflare.}" ] && newip[${#newip[*]}]=shareflare
				[ "$domain" != "${domain//easybytez.}" ] && newip[${#newip[*]}]=easybytez
	# 			[ "$domain" != "${domain//sharpfile.}" ] && newip[${#newip[*]}]=sharpfile
			fi
			[ "$ch_dler" == "1" ] && downloader_in=$dler && unset ch_dler
	
			noproxy
			if [ $multi == 1 ]; then 
				check_stdout
				show_data_stdout
				checked=1
				echo PIPPO
			fi
			while [ -z "$checked" ]; do #file_in
				check_stdout
				show_data_stdout
				sleep 4
				
			done
			
			sleep 1
			unset post_data goal not_available exceeded
		done
	fi
	if [ -f "$path_tmp/links_loop.txt" ]; then
		file="$path_tmp/links_loop.txt"
		
	else
		unset file
		while true; do 
			check_stdout
			show_data_stdout
			sleep 4
			if [ -f "$path_tmp/links_loop.txt" ]; then
				file="$path_tmp/links_loop.txt"
				break
			fi
			
			nodl=0
			for pk in ${killed[*]}; do
				check_tmps=`head -n 1 $path_tmp/*_stdout.tmp 2>/dev/null`
				[ "$check_tmps" != "${check_tmps//$pk}" ] || (( nodl++ ))
			done
			echo KIKKO
			[ $nodl == 0 ] && break
		done
	fi
	## DEBUG
# 	[ ! -f "$path_tmp/links_loop.txt" ] && echo "finito loop"
# 	( [ "${pids_alive[*]}" == "" ] && echo "finito pids" ) || echo "pids: ${pids_alive[*]}"
##

	[ ! -f "$path_tmp/links_loop.txt" ] && [ "${pids_alive[*]}" == "" ] && break
done

separator "-"
print_c 1 "Tutti i link per il download sono stati processati."
separator "-"

#test_cleaning=`ls $path_tmp/*_stdout.tmp 2>/dev/null`
#[ "$test_cleaning" == "" ] && rm -r "$path_tmp"
rm -r "$path_tmp"

echo
echo
if [ -f "$file_log" ]; then
	print_c 3 "In questa directory è presente un file che contiene un elenco di operazioni di $PROG terminate senza successo."
	echo -e "Per leggerlo, digita:\n\n cat $file_log\n\n"
fi


exit
