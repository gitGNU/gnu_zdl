#!/bin/bash -i
#
# ZigzagDownLoader (ZDL)
# 
# This program is free software: you can redistribute it and/or modify it 
# under the terms of the GNU General Public License as published 
# by the Free Software Foundation; either version 3 of the License, 
# or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful, 
# but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY 
# or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License 
# along with this program. If not, see http://www.gnu.org/licenses/. 
# 
# Copyright (C) 2012
# Free Software Foundation, Inc.
# 
# For information or to collaborate on the project:
# https://savannah.nongnu.org/projects/zdl
# 
# Gianluca Zoni
# http://inventati.org/zoninoz
# zoninoz@inventati.org
#


function usage {
	print_c 3 "Uso (l'ordine degli argomenti non è importante): `basename $0` [wget|axel] [file_in] [-m|--multi] [-h|--help] [-c|--configure] [-u|--update] [-clean] [-i|--interactive]"
	echo
	echo -e "$PROG è abilitato per il download da nowdownload, mediafire.com, uploaded.to (ul.to), easybytez.net

$PROG può essere avviato in due modi:

	1) Generando automaticamente un file per la lista dei link per il download (si chiamerà links.txt)
		- apri un terminale ed entra nella directory che dovrà contenere i file scaricati
		- digita il seguente comando e premi invio: $prog 
		- copia i link dei file da scaricare e incollali nel terminale (vai a capo dopo ogni link)
		- premi la chiocciolina \"@\"
		
	2) Utilizzando un file preparato con un editor di testi (andare a capo dopo ogni link)
		- apri un terminale ed entra nella directory che dovrà contenere i file scaricati
		- digita il seguente comando e premi invio: $prog file_in.txt
		

Per i servizi di sharing seguenti è consigliato l'uso della funzione \"multi\" (aggiungere l'argomento -m alle istruzioni sopra elencate) per procedere con il download in parallelo attraverso l'uso di proxy:
uploaded.to (ul.to), easybytez.net

In caso di interruzione del download (per esempio a causa di disconnessione), i file scaricati attraverso Axel possono riprendere il download dal punto di interruzione (solo se nella cartella che contiene il file scaricato è ancora presente anche un file omonimo con estensione \".st\"). $PROG provvederà automaticamente a recuperare il download o a rieseguirlo da capo. Nel caso in cui anche $PROG è stato terminato, il recupero manuale è possibile riavviando $PROG nella seguente forma:
	$prog file_in [-m] [axel|wget]

file_in sta per il nome del file di testo che contiene i link dei file da scaricare. Se il primo download è stato effettuato nel primo modo (vedi sopra, punto 1: generando automaticamente un file per la lista dei link) allora file_in è links.txt. Gli argomenti \"-m\" e \"axel\" (o \"wget\")  sono facoltativi.

Se i file interrotti sono stati scaricati con Wget, non possono essere recuperati e verranno cancellati dalla directory prima di effettuare il riavvio di $PROG. I servizi di file-sharing seguenti sono abilitati solo per il download con Wget: uploaded.to (ul.to), easybytez.net. Gli altri servizi (nowdownload, mediafire.com) sono abilitati di default per Axel e se interrotti possono essere recuperati e completati (automaticamente da $PROG o manualmente riavviando $PROG nella modalità suggerita qui sopra).

L'argomento [wget|axel], wget oppure axel, consente la scelta del downloader. Axel è un acceleratore di download fortemente consigliato e abilitato di default ma disabilitato per alcuni servizi si filesharing. L'argomento [-c|--configure] consente di configurare il downloader di default, cioè di selezionare Wget al posto di Axel senza dover attivare Wget manualmente adottando l'argomento \"wget\".

L'argomento [-clean] cancella eventuali residui di file temporanei di $PROG nella directory di destinazione, prima di iniziare a processare i link immessi dall'utente.

La funzione [-i|--interactive] permette di visualizzare i download \"vivi\" di $PROG anche da un altro terminale oppure nel caso in cui $PROG è terminato (per vostra volontà, premendo Ctrl+C, oppure accidentalmente). Infatti, i download procedono in background e non muoiono insieme a $PROG (tecnicamente possono essere tutti uccisi \"terminando il terminale\"). Per uccidere (definitivamente oppure per riavviarli automaticamente) uno o più processi già avviati, anche con $PROG perfettamente attivo, da un altro terminale entrare nella directory di destinazione e digitare \"$prog -i\" o \"$prog --interactive\": comparirà un'interfaccia (per ora molto rudimentale) con cui poter interagire con i processi di $PROG.

È possibile (ed è raccomandato) far processare, nella stessa lista, link di mirror diversi per uno stesso file (per esempio: vogliamo scaricare file.part1.rar, file.part2.rar e file.part3.rar e abbiamo copie di questi file in uploaded e in easybytez. Si consiglia di usare tutti i link disponili, sia quelli di easybytez che quelli di uploaded: $PROG processerà tutti i link e scaricherà una sola copia dei file, utilizzando il link migliore).

Per aggiornare $PROG è sufficiente usare l'argomento -u (--update).

$PROG funziona anche su Windows. 
Installazione su Windows in due fasi:
	FASE 1 _ Installazione di Cygwin
		- installatore automatico di Cygwin (serve anche ad aggiornare il sistema emulato e ad installare nuovi pacchetti): http://cygwin.com/setup.exe
		- installare il pacchetto \"wget\"

	FASE 2 _ Installazione di $PROG e di Axel
		- salvare nella cartella C:\\\cygwin il seguente file: http://inventati.org/zoninoz/html/upload/files/install_zdl-cygwin.sh
		- avviare cygwin installato nella fase 1 
		- digitare il seguente comando: /install_zdl-cygwin.sh

Uso di $PROG su Windows: avviare cygwin e utilizzare $PROG nel terminale avviato, come descritto in questa guida.

$PROG è rilasciato con licenza GPL (General Public Licence, v.3 e superiori).

Per informazioni e per collaborare al progetto:
https://savannah.nongnu.org/projects/zdl

Gianluca Zoni (zoninoz)
http://inventati.org/zoninoz
"	
	echo
	echo
	exit 1
}


function init {
	log=0
	n=32
	# CYGWIN
	if [ -e "/cygdrive" ];then 
		n=8
		kill -SIGWINCH $$
	fi
	updatecols=`cat ~/.bashrc | grep "shopt -s checkwinsize"`
	[ -z "$updatecols" ] && echo "shopt -s checkwinsize" >> ~/.bashrc && echo "RIAVVIA IL PROGRAMMA: $PROG ha aggiunto in ~/.bashrc l'aggiornamento automatico del rilevamento delle dimensioni del display o della finestra di esecuzione." && exit
	#fi
	multi=0
	prog=`basename $0`
	PROG=`echo $prog | tr a-z A-Z`
	path_tmp=".${prog}_tmp"
	file_log="${prog}_log.txt"
	conf="$HOME/.${prog}rc"
	file_data="$HOME/.${prog}.data"
	
	bar_char="z"
	
	url_update="http://inventati.org/zoninoz/html/upload/files/zdl"
	max_waiting=40
	mkdir -p "$path_tmp"
	
	#user_agent="Mozilla/5.0 (X11; Linux x86_64; rv:10.0.5) Gecko/20100101 Firefox/10.0.5 Iceweasel/10.0.5"
	
	#pid_prog=`ps |grep "$prog" |awk '{ print($1) }'|sed -n "1p"`
	pid_in=1   #$pid_prog
	
	
	rm -f $file_log
	
	if [ -f "$conf" ]; then
		downloader_in=`cat $conf`
	else
		downloader_in=Axel
	fi
	
	init_colors
	data_stdout
	if [ $? == 1 ]; then
		last_stdout=$(( ${#pid_out[*]}-1 ))
		for i in `seq 0 $last_stdout`; do
			check_pid ${pid_out[$i]}
			if [ $? == 1 ]; then
				pids_alive[${#pids_alive[*]}]=${pid_out[$i]}
			fi
		done
	fi
}

#### layout

function init_colors {
	# Reset
	Color_Off='\e[0m'       # Text Reset
	
	# Regular Colors
	Black='\e[0;30m'        # Nero
	Red='\e[0;31m'          # Rosso
	Green='\e[0;32m'        # Verde
	Yellow='\e[0;33m'       # Giallo
	Blue='\e[0;34m'         # Blu
	Purple='\e[0;35m'       # Viola
	Cyan='\e[0;36m'         # Ciano
	White='\e[0;37m'        # Bianco
	
	# Bold
	BBlack='\e[1;30m'       # Nero
	BRed='\e[1;31m'         # Rosso
	BGreen='\e[1;32m'       # Verde
	BYellow='\e[1;33m'      # Giallo
	BBlue='\e[1;34m'        # Blu
	BPurple='\e[1;35m'      # Viola
	BCyan='\e[1;36m'        # Ciano
	BWhite='\e[1;37m'       # Bianco
	
	# Underline
	UBlack='\e[4;30m'       # Nero
	URed='\e[4;31m'         # Rosso
	UGreen='\e[4;32m'       # Verde
	UYellow='\e[4;33m'      # Giallo
	UBlue='\e[4;34m'        # Blu
	UPurple='\e[4;35m'      # Viola
	UCyan='\e[4;36m'        # Ciano
	UWhite='\e[4;37m'       # Bianco
	
	# Background
	On_Black='\e[40m'       # Nero
	On_Red='\e[41m'         # Rosso
	On_Green='\e[42m'       # Verde
	On_Yellow='\e[43m'      # Giallo
	On_Blue='\e[44m'        # Blu
	On_Purple='\e[45m'      # Purple
	On_Cyan='\e[46m'        # Ciano
	On_White='\e[47m'       # Bianco
	
	# High Intensty
	IBlack='\e[0;90m'       # Nero
	IRed='\e[0;91m'         # Rosso
	IGreen='\e[0;92m'       # Verde
	IYellow='\e[0;93m'      # Giallo
	IBlue='\e[0;94m'        # Blu
	IPurple='\e[0;95m'      # Viola
	ICyan='\e[0;96m'        # Ciano
	IWhite='\e[0;97m'       # Bianco
	
	# Bold High Intensty
	BIBlack='\e[1;90m'      # Nero
	BIRed='\e[1;91m'        # Rosso
	BIGreen='\e[1;92m'      # Verde
	BIYellow='\e[1;93m'     # Giallo
	BIBlue='\e[1;94m'       # Blu
	BIPurple='\e[1;95m'     # Viola
	BICyan='\e[1;96m'       # Ciano
	BIWhite='\e[1;97m'      # Bianco
	
	# High Intensty backgrounds
	On_IBlack='\e[0;100m'   # Nero
	On_IRed='\e[0;101m'     # Rosso
	On_IGreen='\e[0;102m'   # Verde
	On_IYellow='\e[0;103m'  # Giallo
	On_IBlue='\e[0;104m'    # Blu
	On_IPurple='\e[10;95m'  # Viola
	On_ICyan='\e[0;106m'    # Ciano
	On_IWhite='\e[0;107m'   # Bianco
}

function print_c {
  case "$1" in
    1)
       echo -n -e '\e[1;32m' #verde
    ;;
    2)
       echo -n -e '\e[0;33m' #giallo
    ;;	
    3)
       echo -n -e '\e[1;31m' #rosso
    ;;	
  esac
  echo -n -e "$2\n"
  echo -n -e '\e[0m'
}

function separator {
	#COLUMNS=$( tput cols ) 2>/dev/null
	[ -z "$COLUMNS" ] && COLUMNS=50
	for column in `seq 1 $COLUMNS`; do echo -n -e "${IBlue}$1${Color_Off}" ; done #\e[1;34m
}

function header {
	echo -n -e "\e[1;34m"ZigzagDownLoader [$PROG]"\e[0m\n"
}



function _log {
	if [ $log == 0 ]; then
		echo -e "I file seguenti non sono stati scaricati perchè già presenti nella directory di destinazione o perché non disponibili (forse solo temporaneamente):\n">$file_log
		log=1
	fi
	date >> $file_log
	
	case $1 in
		1)
			echo
			print_c 3  "File $file_in già presente nella directory di destinazione: non verrà processato."  | tee -a $file_log
			echo
			;;
		2)
			echo
			if [ ! -z "$url_in" ]; then
				url_in_log=" (link di download: $url_in) "
			fi
			print_c 3  "$url_in --> File ${file_in}${link_log}non disponibile, riprovo più tardi"  | tee -a $file_log
			echo
			;;
		3)
			echo
			print_c 3  "$url_in --> Indirizzo errato o file non disponibile" | tee -a $file_log
			echo
			;;
		4)
			echo
			print_c 3 "Il file $file_in supera la dimensione consentita dal server per il download gratuito (link: $url_in)" | tee -a $file_log
			echo
			;;
		5)
			echo
			print_c 3 "Connessione interrotta: riprovo più tardi" | tee -a $file_log
			echo
			;;
		6)
			echo
			print_c 3 "$url_in --> File $file_in troppo grande per lo spazio libero in $PWD su $dev: non sarà scaricato." | tee -a $file_log
			echo
			;;
		7)
			echo
			print_c 3 "$url_in --> File $file_in già in download (${url_out[$i]})" | tee -a $file_log
			echo
			;;
	esac
	
}



#### change IP address

function check_ip {
	if [ "${newip[*]}" != "${newip[*]//$1}" ]; then 
		if [ ! -f "$file_data" ]; then
			new_ip
		else
			[ "$multi" == "1" ] && new_ip
			[ "$multi" == "0" ] && new_ip_router
		fi
	fi
}

function my_ip {
	myip=`wget -q -O - -t 1 -T 20 checkip.dyndns.org|sed -e 's/.*Current IP Address: //' -e 's/<.*$//'`
}

function new_ip_router {
	if [ -f "$file_data" ]; then
		USER=`cat $file_data |awk '{ print($1) }'`
		PASSWD=`cat $file_data |awk '{ print($2) }'`
		print_c 1 "Cambio indirizzo IP..."
		wget --http-passwd=$PASSWD --http-user=$USER 192.168.0.1/stanet.stm  -O - &>/dev/null
		wget --http-passwd=$PASSWD --http-user=$USER --post-data="disconnect=1" 192.168.0.1/cgi-bin/statusprocess.exe -O - &>/dev/null
	else
		echo
		print_c 3 "Funzione di cambio indirizzo IP via router disattivata: non esiste il file di configurazione $HOME/.${prog}.data"
	fi
}

function noproxy {
		unset http_proxy
		export http_proxy
}

function new_ip {
	maxspeed=0
	minspeed=25
	unset close unreached speed
	rm -f "$path_tmp/proxy.tmp"
	#proxy_types=( "Transparent" "Anonymous" "Elite" )
	while true; do
		proxy=""
		#### tipi di proxy: Anonymous Transparent Elite
		proxy_types=( "Transparent" )
		#[ "$domain" != "${domain//mediafire.}" ] && proxy_types=( "Elite" )
		[ "$domain" != "${domain//uploaded.}" ] && proxy_types=( "Anonymous" "Elite" )
		#[ "$domain" != "${domain//shareflare.}" ] && proxy_types=( "Transparent" )
		#[ "$domain" != "${domain//easybytez.}" ] && proxy_types=( "Transparent" )
		ptypes="${proxy_types[*]}"
		print_c 1 "Aggiorna proxy (${ptypes// /, }):"
		old=$http_proxy
		
		noproxy
		line=1
		while [ -z "$proxy" ] ; do		
			#rm -f "$path_tmp/proxy.tmp"
			if [ ! -f "$path_tmp/proxy.tmp" ]; then
				wget -q -t 1 -T 20 --user-agent="Anonimo" http://www.ip-adress.com/proxy_list/ -O "$path_tmp/proxy.tmp" &>/dev/null
				rm -f "$path_tmp/proxy2.tmp"
			fi
			
			for proxy_type in ${proxy_types[*]}; do
				less "$path_tmp/proxy.tmp"|grep "Proxy_Details" |grep "${proxy_type}" >> "$path_tmp/proxy2.tmp"
			done
			
			max=`wc -l "$path_tmp/proxy2.tmp" | awk '{ print($1) }'`
			#cat "$path_tmp/proxy2.tmp"
			string_line=`cat "$path_tmp/proxy2.tmp" |sed -n "${line}p"`
			
			proxy="${string_line#*Proxy_Details\/}"
			[ "$proxy" != "${proxy%:Anonymous*}" ] && proxy_type="Anonymous"
			[ "$proxy" != "${proxy%:Transparent*}" ] && proxy_type="Transparent"
			[ "$proxy" != "${proxy%:Elite*}" ] && proxy_type="Elite"
			proxy="${proxy%:${proxy_type}*}"
			
			z=$(( ${#proxy_done[*]}-1 ))
			if (( $z<0 )) || [ "$z" == "" ]; then z=0 ; fi
			
			for p in `seq 0 $z`; do
				if [ "${proxy_done[$p]}" == "$proxy" ]; then
					proxy=""
				fi
			done
			
			if [ "$string_line" == "" ]; then
					echo -n -e "."
					sleep 3
					(( search_proxy++ ))
					[ $search_proxy == 100 ] && print_c 3 "Finora nessun proxy disponibile: tentativo con proxy disattivato" && noproxy && close=true && break
			fi
			if [ $line == $max ] || [ "$string_line" == "" ]; then
				rm -f "$path_tmp/proxy.tmp"
				line=0
			fi
			(( line++ ))
			[ "$proxy" != "" ] && [ "${proxy_done[*]}" == "${proxy_done[*]//$proxy}" ] && proxy_done[${#proxy_done[*]}]="$proxy"
		done
		unset search_proxy
		[ ! -z $close ] && break
		http_proxy=$proxy
		export http_proxy
		echo -n "Proxy: $http_proxy ($proxy_type)"
		echo
		unset myip
		#my_ip
		#echo "Nuovo IP: $myip"
		print_c 2 "Test velocità di download:"
		index=0
		while (( $index<3 )); do
			index=${#speed[*]}
			speed[$index]=`wget -t 1 -T $max_waiting -O /dev/null "$url_in" 2>&1 | grep '/s'`  #'\([0-9.]\+ [KM]B/s\)'`
			speed[$index]="${speed[$index]#*'('}"
			show_speed="${speed[$index]## }"
			show_speed="${show_speed%%)*}"
			if [ "${speed[$index]}" != "${speed[$index]% B/s*}" ]; then
				speed[$index]="0"
			elif [ "${speed[$index]}" != "${speed[$index]//'KB/s'}" ]; then
				speed[$index]="${speed[$index]%%' '*}"
				speed[$index]="${speed[$index]%','*}"
			elif [ "${speed[$index]}" != "${speed[$index]//'MB/s'}" ]; then
				speed[$index]="${speed[$index]%%' '*}"
				speed[$index]="${speed[$index]//,/.}"
				speed[$index]="${speed[$index]%% *}"
				speed[$index]=`echo "${speed[$index]}*1024" | bc -l`
				speed[$index]="${speed[$index]%'.'*}"
			fi
			if [ "${speed[$index]}" == "" ]; then
				#print_c 3 "Download interrotto"
				#unreached="true"
				#break
				speed[$index]=0
				show_speed="0 B/s"
			fi
			
			echo "$show_speed"
		done 2>/dev/null
		
		if [ -z $unreached ]; then
			
			for k in ${speed[*]}; do  
				if (( $maxspeed<$k )); then 
					maxspeed=$k 
				fi 
			done
			
			if (( $maxspeed<$minspeed )); then
				print_c 3 "La massima velocità di download raggiunta usando il proxy è inferiore a quella minima richiesta ($minspeed KB/s)"
				#unset $proxy
				
			else
				print_c 1 "Massima velocità di download raggiunta usando il proxy $http_proxy: $maxspeed KB/s"
				break
			fi 2>/dev/null
		fi
		unset unreached speed
	done
	unset maxspeed
	echo
	rm -f "$path_tmp/proxy.tmp"
	old_proxy="$proxy"
}

#### hacking web pages



function get_tmps {
	while [ "`less $path_tmp/zdl.tmp |grep \</html`" == "" ]; do
		#print_c 2 "\nAttendi..."
		wget -t 5 -T $max_waiting --retry-connrefused --save-cookies=$path_tmp/cookies.zdl -O "$path_tmp/zdl.tmp" $url_in  &>/dev/null
		echo -e "...\c"
	done
}

function input_hidden {
	j=1
	less $tmp | grep input | grep hidden > $path_tmp/data.tmp
	max=`wc -l "$path_tmp/data.tmp" | awk '{ print($1) }'`
	max=$(( $max+1 ))
	
	while [ $j != $max ]; do
		data=`less $path_tmp/data.tmp |sed -n "${j}p"`
		
		name=${data#*name=\"}
		name=${name%%\"*}
		value=${data#*value=\"}
		value=${value%%\"*}
		
		if [ "$name" == "realname" ] || [ "$name" == "fname" ]; then # <--easybytez e sharpfile
			nomefile="$value"
		fi

		if [ "$post_data" == "" ]; then
			post_data="${name}=${value}"
		else
			post_data="${post_data}&${name}=${value}"
		fi
		(( j++ ))
	done
}


function pseudo_captcha {
	j=0
	for cod in ${ascii_dec[*]}; do 
		captcha[$j]=`printf "\x$(printf %x $cod)"`
		(( j++ ))
	done
}



#### Axel

function check_downloader {
	if [ "$downloader_in" == "Axel" ]; then
		while [ -z "`which axel 2>/dev/null`" ]; do
			clear
			print_c 3 "ATTENZIONE: Axel non è installato nel tuo sistema"
			
			echo -e "$PROG può scaricare con Wget ma raccomanda fortemente Axel, perché:\n
		- può accelerare sensibilmente il download
		- permette il recupero dei download in caso di interruzione
		
	Per ulteriori informazioni su Axel: http://alioth.debian.org/projects/axel/
	
	1) Installa automaticamente Axel da pacchetti
	2) Installa automaticamente Axel da sorgenti
	3) Esci da $PROG per installare Axel manualmente (puoi trovarlo qui: http://pkgs.org/search/?keyword=axel)
	4) Ignora Axel e continua con Wget
	5) Configura Wget di default
	6) Ripristina la condizione iniziale (Axel di default)"
	
			print_c 2 "Scegli cosa fare (1-6)"
			read input
			
			case $input in
			
			1) install_pk ;;
			2) install_src ;;
			3) exit ;;
			4) downloader_in=Wget ; break ;;
			5) echo Wget > $conf ;;
			6) rm $conf ;;
			
			esac
		done
	fi
}

function install_test {
	
	if [ -z "`which axel 2>/dev/null`" ]; then
		print_c 3 "Installazione automatica non riuscita"
		case $1 in
			pk) echo "$2 non ha trovato il pacchetto di Axel" ;;
			src) echo "Errori nella compilazione o nell'installazione";;
		esac
	fi
	echo
	print_c 2 "<Premi un tasto per continuare>"
	read
}

function install_pk {
	print_c 1 "Installo Axel ..."
	if [ `which apt-get 2>/dev/null` ]; then
		DEBIAN_FRONTEND=noninteractive sudo apt-get --no-install-recommends -q -y install axel || (  echo "Digita la password di root" ; DEBIAN_FRONTEND=noninteractive su -c "apt-get --no-install-recommends -q -y install axel" )
		install_test pk apt-get
	elif [ `which yum 2>/dev/null` ]; then
		sudo yum install axel || ( echo "Digita la password di root" ; su -c "yum install axel" )
		install_test pk yum
	elif [ `which pacman 2>/dev/null` ]; then
		sudo pacman -S axel 2>/dev/null || ( echo "Digita la password di root" ; su -c "pacman -S axel" )
		install_test pk pacman
	else
		install_test
	fi
}

function install_src {
	cd /usr/src
	wget http://alioth.debian.org/frs/download.php/3015/axel-2.4.tar.gz
	tar zxvf axel-2.4.tar.gz
	cd axel-2.4
	
	make
	sudo make install || ( echo "Digita la password di root" ; su -c "make install" )
	make clean
	install_test src
	cd -
}

function configure {
	echo
	print_c 3 "CONFIGURAZIONE DI $PROG"
	echo "Il downloader attuale di $PROG è $downloader_in"
	echo
	print_c 2 "Scegli il downloader (wget|axel):"
	read dloader
	case $dloader in
		wget) 
			downloader_in=Wget
		;;
		axel) 
			downloader_in=Axel
		;;
		*)
			print_c 3 "Downloader non riconosciuto: puoi scegliere solo wget o axel"
			exit 1
		;;
	esac
	echo $downloader_in > $conf
	echo
	print_c 1 "$PROG scaricherà con $downloader_in"
	exit
}

#### ZDL

function check_freespace {
	if [ -f ${file_in}_stdout.tmp ]; then
		data_stdout $path_tmp/${file_in}_stdout.tmp
		if [ $? == 1 ]; then
			fsize=$(( ${lenght_out[0]}/1024 ))
		else
			fsize=0
		fi
	else
		fsize=0
	fi
	
	mkdir -p $path_tmp
	df > $path_tmp/df.tmp
	
	maxl=`wc -l $path_tmp/df.tmp |awk '{ print($1) }'`
	pattern=`ls -l "$PWD"`
	pattern="${pattern#*-> }"
	for l in `seq 2 $maxl`; do
		dev=`cat $path_tmp/df.tmp | awk '{ print($6) }' | sed -n "${l}p"`
		if [ "$dev" == "/" ]; then dev="/home" ; fi
		freespace=`cat $path_tmp/df.tmp | awk '{ print($4) }' | sed -n "${l}p"`
		
		if [ "$pattern" != "${pattern//$dev}" ]; then
			if (( $freespace<5000 )); then
				print_c 3 "Spazio insufficiente sul device. $PROG terminato."
				exit
			elif [ $fsize != 0 ] && (( $freespace<$fsize )); then
				kill $pid_in
				_log 6
			fi
		fi
	done
	unset fsize
}



function download {
	#[ -f "$file_in" ] && read -p "ERRORE: $file_in c'è già!! programma terminato"
	rm -f "$path_tmp/${file_in}_stdout.tmp"
	if [ "$downloader_in" = "Axel" ]; then
		export AXEL_COOKIES=$path_tmp/cookies.zdl
		
		[ "$file_in" != "" ] && argout="-o"
		axel -n $n "$url_in_file" $argout "$file_in" >> "$path_tmp/${file_in}_stdout.tmp" & 
		pid_in=$!
		echo -e "${pid_in}\nlink_${prog}: $url_in\nAxel" > "$path_tmp/${file_in}_stdout.tmp"
		
	elif [ "$downloader_in" = "Wget" ]; then
		#--progress=bar:force
		[ "$file_in" != "" ] && argout="-O" && fileout="$file_in"
		[ "$domain" != "${domain//easybytez.}" ] && unset argout fileout
		LANG='en_US.UTF-8' wget -t 1 -T $max_waiting --retry-connrefused -c -nc --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl  --post-data="${post_data}" "$url_in_file" -S  $argout "$fileout" -a "$path_tmp/${file_in}_stdout.tmp" & 
		pid_in=$!
		echo -e "${pid_in}\nlink_${prog}: $url_in\nWget" > "$path_tmp/${file_in}_stdout.tmp"
	fi
	unset post_data checked
}

function check_pid {
	if [ ! -z $1 ]; then
		pid=$1
		ps au | awk '{print $2}' | while read alive; do
			if [ "$alive" == "$pid" ]; then
				return 1
			fi
		done
	fi
}


function show_data_alive {
	data_alive
	if [ ! -z $alive ]; then 
		unset alive

		print_c 1 "Processi di download attualmente in vita:"
		separator "="
		last_alive=$(( ${#pid_alive[*]}-1 ))
		for j in `seq 0 $last_alive`; do
			print_c 1 "Numero download attivo: $j"
			[ ! -f "${file_alive[$j]}" ] && print_c 3 "${downloader_alive[$j]} sta scaricando a vuoto: ${file_alive[$j]} non esiste"
			init_colors
			echo -e "${BBlue}File:${Color_Off} ${file_alive[$j]}" 
			[ ! -z "${alias_file_alive[$j]}" ] && echo "${BBlue}Alias:${Color_Off} ${alias_file_alive[$j]}"
			echo -e "${BBlue}Downloader:${Color_Off} ${downloader_alive[$j]}\n${BBlue}Link:${Color_Off} ${url_alive[$j]}"
			echo -e "${BBlue}Progresso:${IYellow} ${progress_alive[$j]}${Color_Off}"
			
			if [ $j != $last_alive ]; then 
				separator "-"
			else
				separator "="
			fi
		done
		return 1
	else
		separator "="
		print_c 3  "Nessun download attivo di $PROG rilevato"
		separator "="
	fi
}

function data_alive {
	data_stdout
	if [ $? == 1 ]; then
		client=1
		tot=$(( ${#pid_out[*]}-1 ))
		j=0
		for i in `seq 0 $tot`; do
			check_pid ${pid_out[$i]}
			if [ $? == 1 ]; then
				pid_alive[$j]="${pid_out[$i]}"
				file_alive[$j]="${file_out[$i]}"
				downloader_alive[$j]="${downloader_out[$i]}"
				alias_file_alive[$j]="${alias_file_out[$i]}"
				url_alive[$j]="${url_out[$i]}"
				progress_alive[$j]="${progress_out[$i]}"
				length_alive[$j]=${length_out[$i]}
				alive=1
				(( j++ ))
				
			fi
		done
	fi
}

function interactive {
	echo
	echo
	client=1
	show_data_alive
	if [ $? == 1 ]; then
		echo
		echo
		separator "?"
		print_c 2 "Seleziona i numeri dei download attivi da riavviare o eliminare, separati da spazi (digita Ctrl+C per uscire subito):"
		read input
		inputs=( $input )
		last_alive=$(( ${#pid_alive[*]}-1 ))
		options=`seq 0 $last_alive`
		while [ "$input2" != "e" ] && [ "$input2" != "r" ] && [ "$input2" != "t" ]; do
			print_c 2 "Vuoi che i download selezionati siano terminati definitivamente oppure che siano riavviati automaticamente più tardi?"
			echo
			echo -e "	r) per riavviarli digita \"r\"
	e) per eliminarli definitivamente (e cancellare il file), digita \"e\"
	t) per terminare il programma senza fare niente digita \"t\""
			
			print_c 2 "Scegli cosa fare: [r | e | t]"
			read input2
			
			if [ "$input2" == "e" ] || [ "$input2" == "r" ]; then
				for i in ${inputs[*]}; do
					if [ "${options}" != "${options//$i}" ]; then
						kill ${pid_alive[$i]}
						rm -f "${file_alive[$i]}" "${alias_file_alive[$i]}" # "${file_alive[$i]}_stdout.tmp"
					fi
				done
				if [ "$input2" == "e" ]; then
					for i in ${inputs[*]}; do
						if [ "${options}" != "${options//$i}" ]; then
							links_loop - "${url_alive[$i]}"
						fi
					done
				fi
			elif [ "$input2" == "t" ]; then
				print_c 1  "Nessun processo riavviato o eliminato"
				
			fi
		done
	fi
	exit
}


function data_stdout {
	unset list file_stdout file_out alias_file_out url_out downloader_out pid_out length_out
	if [ ! -z "$1" ];then # arg=$path_tmp/${file_in}_stdout.tmp
		list="$1"
	else
		list=`ls -1 $path_tmp/*_stdout.tmp 2>/dev/null`
	fi
	if [ ! -z "$list" ]; then
		
		i=0
		for item in $list; do
			
			file_stdout=$item

			file_o="${file_stdout//_stdout.tmp}"
			file_o="${file_o#$path_tmp/}"
			file_out[$i]=`cat "$file_stdout"|grep "Saving to"`
			file_out[$i]="${file_out[$i]#*Saving to: \`}"
			file_out[$i]="${file_out[$i]%\'*}"
			
			
			if [ ! -z "${file_out[$i]}" ] && [ "$file_o" != "${file_out[$i]}" ]; then
				print_c 3 "Errore nei dati: il file $file_stdout contiene i dati di ${file_out[$i]}"
				exit 1
			fi
			
			if [ -z "${file_out[$i]}" ]; then
				file_out[$i]="$file_o"
			fi
			
			pid_out[$i]=`head -n 1 $file_stdout #"$path_tmp/head_stdout"`
						
			url_out[$i]=`cat $file_stdout|grep "link_$prog"`
			url_out[$i]="${url_out[$i]#link_${prog}: }"
			#progress_out[$i]=`tail "$file_stdout" |grep K |grep % |tail -n 1`
			
			downloader_out[$i]=`head -n 3 $file_stdout|sed -n '3p'`
			progress_data=`tail "$file_stdout" |grep K |grep % |tail -n 1`
			progress_data="${progress_data//'..........'}"
			progress_data="${progress_data//[\[\]]}"
			
			if [ "${downloader_out[$i]}" == "Wget" ]; then
				if [ "${file_out[$i]}" != "${file_out[$i]%.alias}" ];then
					alias_file_out[$i]="${file_out[$i]}"
					file_out[$i]=`cat $file_stdout |grep filename`
					file_out[$i]="${file_out[$i]#*'filename="'}"
					file_out[$i]="${file_out[$i]%'"'*}"
					file_stdout="$path_tmp/${alias_file_out[$i]}_stdout.tmp"
				fi
				length_out[$i]=`cat $file_stdout |grep "Length:" |tail -n 1`
				length_out[$i]="${length_out[$i]#*Length: }"
				length_out[$i]="${length_out[$i]%%' '*}"
				
				percent=`echo $progress_data | awk '{ print($2) }'`
				eta=`echo $progress_data | awk '{ print($4) }'`
				speed=`echo $progress_data | awk '{ print($3) }'`
				type_speed="${speed//[0-9.,]}"
				num_speed="${speed//$type_speed}"
				case $type_speed in
					B) type_speed="B/s";;
					K) type_speed="KB/s";;
					M) type_speed="MB/s";;
				esac
				speed="${num_speed}${type_speed}"
			elif [ "${downloader_out[$i]}" == "Axel" ]; then
				length_out[$i]=`cat "$file_stdout" |grep 'File size'`
				length_out[$i]="${length_out[$i]#*File size: }"
				length_out[$i]="${length_out[$i]%% *}"
				
				speed=`echo $progress_data | awk '{ print($2) }'`
				
				type_speed="${speed//[0-9.,]}"
				num_speed="${speed//$type_speed}"
				case $type_speed in
					KB/s) num_speed=$(( $num_speed*1024 ));;
					MB/s) num_speed=$(( $num_speed*1024*1024 ));;
				esac
				if [ ! -z $num_speed ] && [ $num_speed != 0 ]; then	
					[ -f "${file_out[$i]}" ] && length_saved=`ls -l "${file_out[$i]}" | awk '{ print($5) }'`
					seconds=0
					minutes=0
					hours=0
					seconds=$(( (${length_out[$i]}-$length_saved)/$num_speed ))
					minutes=$(( $seconds/60 ))
					hours=$(( $minutes/60 ))
					speed="${speed//,/.}"
					eta="${hours}h${minutes}m"
					percent=`echo $progress_data | awk '{ print($1) }'`
				fi
			fi
			if [ ! -z "$num_speed" ] && [ "$num_speed" != "0" ] && [ "$num_percent" != ".." ]; then
				num_percent=0
				num_percent=${percent//'%'}
				size_bar=0
				size_bar=$(( ($COLUMNS/2)*$num_percent/100 ))
				diff_size_bar=$(( ($COLUMNS/2)-$size_bar ))
				
				unset bar diff_bar
				for column in `seq 1 $size_bar`; do
					bar="${bar}${bar_char}"
				done
				for column in `seq 1 $diff_size_bar`; do
					diff_bar="${diff_bar} "
				done
				#echo "$COLUMNS = $size_bar + $diff_size_bar"
				bar="[${bar}>${diff_bar}]"
				progress_out[$i]="${bar} $percent $speed $eta"
			else
				progress_out[$i]=""
			fi
			
			(( i++ ))
		done
		unset length_saved
		return 1
	fi
}

function show_data_stdout {
	data_stdout
	if [ $? == 1 ]; then		
		print_c 1 "\nDownloading..."
		separator "="
		last_stdout=$(( ${#pid_out[*]}-1 ))
		for i in `seq 0 $last_stdout`; do
			length_saved=0
			[ -f "${file_out[$i]}" ] && length_saved=`ls -l "${file_out[$i]}" 2>/dev/null| awk '{ print($5) }'`
			echo -e "${BBlue}File:${Color_Off} ${file_out[$i]} ${BBlue}Downloader:${Color_Off} ${downloader_out[$i]}\n${BBlue}Link:${Color_Off} ${url_out[$i]}"
			progress="${progress_out[$i]}"
			color=2
			
			check_pid ${pid_out[$i]}
			if [ $? != 1 ]; then
				progress="Download non attivo"
				color=3
			fi
			if [ -f "${file_out[$i]}" ] && [ ! -f "${file_out[$i]}.st" ] && [ "$length_saved" == "${length_out[$i]}" ];then
				progress="Download completato"
				color=1
			fi
			print_c $color "${progress}"
			if [ $i != $last_stdout ] && [ "$multi" == "1" ]; then
				separator "-"
			else
				separator "="
			fi
		done
	else
		separator "="
		print_c 3 "Nessun download attivo"
		separator "="
	fi
	echo
	sleep 5
}

function check_stdout {
	unset checked
	data_stdout
	if [ $? == 1 ]; then
		last_stdout=$(( ${#pid_out[*]}-1 ))
		for ck in `seq 0 $last_stdout`; do
			check_pid ${pid_out[$ck]}
			if [ $? == 1 ]; then
				if [ -f "${file_out[$ck]}" ] && [ -f "${alias_file_out[$ck]}" ]; then
					rm -f "${alias_file_out[$ck]}"
				fi
				if [ ! -f "${file_out[$ck]}" ] && [ ! -f "${alias_file_out[$ck]}" ]; then
					kill ${pid_out[$ck]}
				else
					pids_alive[${#pids_alive[*]}]=${pid_out[$ck]}
					[ ! -z $pid_in ] && [ "${pid_in}" == "${pid_out[$ck]}" ] && downloading=1
				fi
			fi
			
			check_pid ${pid_out[$ck]}
			if [ $? != 1 ]; then
				length_saved=0
				[ -f "${file_out[$ck]}" ] && length_saved=`ls -l "${file_out[$ck]}" | awk '{ print($5) }'`
				
				already_there=`cat "$path_tmp/${file_out[$ck]}_stdout.tmp" 2>/dev/null |grep 'already there; not retrieving.'`
				if [ -z "$already_there" ]; then 
					unset already_there
					
					if [ "${length_out[$ck]}" == "0" ] || ( [ ! -z "${length_out[$ck]}" ] && (( ${length_out[$ck]} > 0 )) && (( $length_saved < ${length_out[$ck]} )) ); then
						[ ! -f "${file_out[$ck]}.st" ] && rm -f "${file_out[$ck]}"
						#_log 5
						#checked=1
					fi
					if ( [ ! -z "${length_out[$ck]}" ] && [ "${length_out[$ck]}" != "0" ] && (( $length_saved == ${length_out[$ck]} )) && (( ${length_out[$ck]} > 0 )) ); then 
						links_loop - "${url_out[$ck]}"
					fi

				else # file exists: don't loop its url_out
					#checked=1
					print_c 3 "Errore: $path_tmp/${file_out[$ck]}_stdout.tmp  --> \"already there; not retrieving.\": $PROG ha cercato di scaricare di nuovo un file già esistente nella directory di destinazione"
					read -p "ATTENZIONE!"
					rm -f "$path_tmp/${file_out[$ck]}_stdout.tmp"
					#links_loop - "${url_out[$ck]}"
					#_log 1
				fi
				
				# "$path_tmp/${file_out[$ck]}_stdout.tmp" NON VALIDO -->cancellato solo se MORTO
# 				msg=`cat "$path_tmp/${file_out[$ck]}_stdout.tmp" |grep "Proxy request sent, awaiting response... Read error"`
# 				
# 				if [ ! -z "$msg" ] || [ "${length_out[$ck]}" == "unspecified" ] || [ "${length_out[$ck]}" == 0 ] || [ -z "${length_out[$ck]}" ]; then
# 					[ ! -f "${file_out[$ck]}.st" ] && rm "$path_tmp/${file_out[$ck]}_stdout.tmp"
# 				fi
			fi
		done
		return 1
	#else
		#checked=1
	fi
	[ ! -z "$downloading" ] && print_c 1 "downloading --> $file_in ..."
	unset downloading
}

function check_alias {
	# if file_in is an alias...
	
	if [ -f "$file_in" ] && [ -f "$path_tmp/${file_in}_stdout.tmp" ] && [ "${file_in}" != "${file_in%.alias}" ]; then
		data_stdout
		if [ $? == 1 ]; then
			last_stdout=$(( ${#pid_out[*]}-1 ))
			#read -p ${#pid_out[*]}
			for i in `seq 0 $last_stdout`; do
				check_pid ${pid_out[$i]}
				if [ $? == 1 ]; then
					check_pid ${pid_in}
					if [ $? == 1 ]; then
						unset real_file_in 
						real_file_in=`cat $path_tmp/${file_in}_stdout.tmp |grep filename`
						real_file_in="${real_file_in#*'filename="'}"
						real_file_in="${real_file_in%'"'*}"
						
						file_in_alias="${file_in}"
						file_in="${real_file_in}"
						
						if [ "${pid_out[$i]}" != "$pid_in" ] && [ "$file_in" == "${file_out[$i]}" ]; then
							kill $pid_in
							rm -f  "${file_in_alias}"
						elif [ "${pid_out[$i]}" == "$pid_in" ] && [ "$file_in" == "${file_out[$i]}" ]; then
							check_in # se file_in esiste, ne verifica la validità --> potrebbe cancellarlo
							if [ ! -f "$file_in" ]; then
								mv "$file_in_alias" "$file_in"
								print_c 1 "$file_in_alias rinominato come $file_in"
							else
								kill $pid_in
								rm -f  "${file_in_alias}"
							fi
						fi
					fi
					
					check_pid ${pid_in}
					if [ $? != 1 ] && [ "${pid_out[$i]}" != "$pid_in" ] && [ "$file_in" == "${file_out[$i]}" ]; then
						rm -f "${file_in}"
					fi
				fi
			done
		fi
	fi
}


function check_in {
	if [ -z "$file_in" ]; then
		unset alive jump
		# alive
		data_alive
		if [ ! -z $alive ]; then 
			
			last_alive=$(( ${#pid_alive[*]}-1 ))
			for i in `seq 0 $last_alive`; do
				if [ "${url_alive[$i]}" == "$url_in" ]; then
					jump=1
					return 3
				fi
			done
			
		fi
		#  file_in
		if [ ! -z "${pid_out[*]}" ]; then 
			
			last_stdout=$(( ${#pid_out[*]}-1 ))
			for i in `seq 0 $last_stdout`; do
				if [ "${url_out[$i]}" == "$url_in" ]; then
					file_in="${file_out[$i]}"
				fi
			done
			
		fi
	fi
	if [ ! -z "$file_in" ]; then
		if [ -f "$file_in" ]; then
			data_stdout
			if [ $? == 1 ]; then
				last_stdout=$(( ${#pid_out[*]}-1 ))
				for i in `seq 0 $last_stdout`; do
					if [ "${file_out[$i]}" == "$file_in" ] || [ "$file_in" == "${alias_file_out[$i]}" ]; then
						check_pid ${pid_out[$i]}
						if [ $? == 1 ]; then
							#_log 7
							return 1
							
						fi
						
						check_pid ${pid_out[$i]}
						if [ $? != 1 ]; then
							
							length_saved=0
							length_alias_saved=0
							length_saved=`ls -l "${file_in}" | awk '{ print($5) }'`
							[ -f "${alias_file_out[$i]}" ] && length_alias_saved=`ls -l "${alias_file_out[$i]}" | awk '{ print($5) }'`
						
							if [ "${length_out[$i]}" == "unspecified" ] || ( [ ! -z "${length_out[$i]}" ] && (( ${length_out[$i]}>$length_saved )) && (( ${length_out[$i]}>$length_alias_saved )) ); then
							
								if [ ! -f "${file_in}.st" ]; then
									rm -f "$file_in"
									return 2
								fi
							fi
						fi
					fi
				done
			fi
		fi
	fi
}


function links_loop { 	#usage with op=+|- : links $op $link
	op="$1" #operator
	url_loop="$2" #url
	if [ ! -z "$url_loop" ]; then
		case $op in
			+)	
				if [ -f "$path_tmp/links_loop.txt" ]; then
					lnx=`cat $path_tmp/links_loop.txt`
					for lnk in $lnx; do
						[ "${url_loop//$lnk}" == "${url_loop}" ] && echo "$lnk" >> $path_tmp/links_loop2.txt
					done
					[ -f $path_tmp/links_loop2.txt ] && mv $path_tmp/links_loop2.txt $path_tmp/links_loop.txt
				fi
				echo "$url_loop" >> $path_tmp/links_loop.txt
				
				;;
			-)
				if [ -f "$path_tmp/links_loop.txt" ]; then
					lnx=`cat $path_tmp/links_loop.txt`
					for lnk in $lnx; do
						[ "${url_loop//$lnk}" == "${url_loop}" ] && echo "$lnk" >> $path_tmp/links_loop2.txt
					done
					rm $path_tmp/links_loop.txt
					[ -f $path_tmp/links_loop2.txt ] && mv $path_tmp/links_loop2.txt $path_tmp/links_loop.txt
				fi
				;;
			in) 
				lnx=`cat $path_tmp/links_loop.txt 2>/dev/null`
				if [ ! -z "$lnx" ];then
					for lnk in $lnx; do
						if [ "${url_loop//$lnk}" != "${url_loop}" ]; then 
							return 1
						else
							return 5
						fi
					done
				else
					return 5
				fi
				;;
		esac
	fi
}

function init_links_loop {
	
	if [ -f $file ]; then
		urls=`cat $file`
		for url in $urls; do
			links_loop + $url
		done
		data_stdout
		if [ $? == 1 ]; then
			last_stdout=$(( ${#pid_out[*]}-1 ))
			for i in `seq 0 $last_stdout`; do
				links_loop + "${url_out[$i]}"
			done
		fi
	fi
}

function sanitize {
	if [ ! -f "${file_in}.st" ] && [ -f "${file_in}" ] && [ "$downloader_in" = "Axel" ]; then
		_log 1
		no_newip=true
	elif ( [ -f "${file_in}" ] || [ -f "${path_tmp}/${file_in}" ] ) && [ "$downloader_in" = "Wget" ]; then
		no_newip=true
		[ $? != 1 ] && _log 1
	elif [ ! -z "$not_available" ]; then
		[ ! -z "$url_in_file" ] && _log 3
		no_newip=true
	elif [ ! -z "$exceeded" ]; then
		_log 4
		no_newip=true
	elif [ "$url_in_file" == "" ] || [ "${file_in}" == "" ]; then
		_log 2
		unset no_newip
	elif [ "$url_in_file" != "${url_in_file//{\"err\"/}" ]; then
		_log 2
		unset no_newip
	elif [ ! -z "$url_in_file" ] && ( ( ( [ -f "${file_in}.st" ] || [ ! -f "${file_in}" ] ) && [ "$downloader_in" = "Axel" ] ) || ( ( [ ! -f "${file_in}" ] && [ ! -f "${path_tmp}/${file_in}" ] ) && [ "$downloader_in" = "Wget" ] ) ); then
		return 6
	fi
}

init

################################### HEADER
header
separator z
###################################
for arg in $@ ; do
	case "$arg" in
		-i|--interactive)
			interactive
			;;
		-clean)
			( rm -r "$path_tmp"/* 2>/dev/null && print_c 1 "File temporanei cancellati" ) || print_c 3 "Pulizia file temporanei non effettuata (file inesistenti)"
			;;
		-u | --update)
			print_c 1 "Aggiornamento di $PROG ..."
			wget -T $max_waiting "$url_update" -O /tmp/$prog 
			print_c 1 "Installazione di $PROG in /usr/local/bin/"
			( mv /tmp/$prog /usr/local/bin/$prog ; chmod +x /usr/local/bin/$prog ; print_c 1 "Aggiornamento completato." ) || ( sudo mv /tmp/$prog /usr/local/bin/$prog ; sudo chmod +x /usr/local/bin/$prog ; print_c 1 "Aggiornamento completato." ) || ( echo -n "(Root)" ; su -c "mv /tmp/$prog /usr/local/bin/$prog ; chmod +x /usr/local/bin/$prog" ; print_c 1 "Aggiornamento completato." ) || ( print_c 3 "Aggiornamento automatico non riuscito" )
			echo "which ${prog}:"
			which $prog
			echo
			;;
		wget)
			downloader_in=Wget
			;;
		axel)
			downloader_in=Axel
			;;
		
		-m | --multi)
			multi=1
# 			if [ -e "/cygdrive" ]; then
# 				export DISPLAY=:0
# 				X &>/dev/null &
# 				exec aewm++ &>/dev/null &
# 			fi
			;;
		
		-h | --help)
			usage
			;;
			
		-c | --configure)
			configure
			;;
		
		*)
			if [ -f "$arg" ]; then
				file="$arg"
			else
				print_c 3 "Il file $arg non esiste"
				echo
				usage
			fi
			;;
	esac
done

check_downloader

print_c 1 "Download con $downloader_in"


if [ -f "$file_log" ]; then
	log=1
fi

if [ "$file" == "" ] ; then 
	print_c 2 "Incolla la lista dei link (nowdownload, mediafire, uploaded, ul, easybytez) poi digita @" 
	echo "[per uscire da $PROG digita ctrl+c]"
	read -d @ -a links
	printf "%s\n" "${links[@]}" > links.txt
	file="links.txt"
	echo
fi



#converti UL.TO in UPLOADED.TO/FILE
lnks=`cat $file`
rm $file

echo -e "${lnks// /\n}" | while read line ; do 
	if [ "$line" != "${line//http:\/\/ul.to/}" ]; then
		line=${line//ul.to/uploaded.to/file}
		
		
	fi
	echo $line >> $file
done


init_links_loop

while true; do
	if [ -f "$file" ]; then	
		links_in=`cat $file`
		for url_in in $links_in; do
			[ ! -z "$pid_in" ] && check_freespace
			
			unset pid_in checked file_in url_in_file 			
			check_in
			if [ $? == 3 ];then
				sleep 1
			else
				domain=${url_in//\?*}
				echo > $path_tmp/zdl.tmp > $path_tmp/zdl2.tmp
				
				echo
				separator "Z"
				
				echo -e "\nLink da processare: $url_in"
				
		# 		if [ "$domain" != "${domain//4us.to/}" ]; then
		# 			
		# 			## 4US.TO ###############
		# 			get_tmps		
		# 			link=`cat $path_tmp/zdl.tmp | grep morpheus `
		# 			link=${link#*document.location=\"}
		# 			link=${link%\"*}
		# 			
		# 			file_in=${link##*=} 
		# 			n=1
		# 	
				if [ "$domain" != "${domain//mediafire.}" ]; then
					
					# MEDIAFIRE.COM ##############
					check_ip mediafire
					
					get_tmps
					url_in_file=`cat $path_tmp/zdl.tmp |grep 'kNO = '`
					url_in_file=${url_in_file#*'kNO = "'}
					url_in_file=${url_in_file//\" onclick=\"avh*/}
					url_in_file=${url_in_file%'"'*}
					
					file_in=${url_in_file##*'/'}
					n=4
				elif [ "$domain" != "${domain//nowdownload.}" ]; then
					
					## http://www.nowdownload ###########
					
					get_tmps
					token=`cat $path_tmp/zdl.tmp | grep token`
					token=${token//*=}
					token=${token//\"*/}
					preurl_in_file=${url_in//\/dl/\/dl2}"/$token"
					print_c 2 "Attendi circa 30 secondi:"
					k=`date +"%s"`
					s=0
					unset url_in_file
					while true; do
	
						if (( $s>29 )); then
							wget -t 1 -T $max_waiting --load-cookies=$path_tmp/cookies.zdl -O "$path_tmp/zdl2.tmp" "$preurl_in_file" &>/dev/null 
						fi
						sleep 1
						s=`date +"%s"`
						s=$(( $s-$k ))
						
						echo -e $s"\r\c"
						
						url_in_file=`cat $path_tmp/zdl2.tmp |grep "Click here to download" 2>/dev/null`
						url_in_file=${url_in_file//*href=\"} 
						url_in_file=${url_in_file//\"*}
	
						[ ! -z "$url_in_file" ] && break
					done	
					file_in1=`cat $path_tmp/zdl.tmp | grep 'Downloading'`
					file_in1="${file_in1#*'<br> '}"
					file_in1="${file_in1%%</h4>*}"
					file_in1="${file_in1%' '*}"
					file_in1="${file_in1%' '*}"
					file_in1="${file_in1%' '*}"
					file_in1="${file_in1//'<br>'/}"
					while [ "$file_in1" != "${file_in1%.}" ]; do
						file_in1=${file_in1%.}
					done
					file_in2="${url_in_file//*'/'}"
					file_in2="${file_in2#*_}"
					
					
					if [ "$file_in2" != "${file_in2//$file_in1}" ]; then
						file_in="$file_in2"
					else
						file_ext="${file_in2##*.}"
						file_in="${file_in1}.${file_ext}"
					fi
					
		# 		elif [ "$domain" != "${domain//sharpfile.}" ]; then
		# 			wget $url_in -O $path_tmp/zdl.tmp &>/dev/null
		# 			tmp="$path_tmp/zdl.tmp"
		# 			input_hidden
		# 			
		# 			if ( [ ! -f "${file_in}.st" ] && [ -f "${file_in}" ] && [ "$downloader_in" = "Axel" ] ) || ( [ -f "${file_in}" ] && [ "$downloader_in" = "Wget" ] ); then
		# 				echo -n
		# 			else
		# 				check_ip sharpfile
		# 				wget --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl $url_in -O $path_tmp/zdl.tmp &>/dev/null
		# 				echo -e "...\c"
		# 				tmp="$path_tmp/zdl.tmp"
		# 				input_hidden
		# 				
		# 				post_data="${post_data//'op=catalogue&'}"
		# 				
		# 				wget --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies2.zdl --post-data="$post_data&method_free=Free Download" $url_in -O $path_tmp/zdl2.tmp &>/dev/null
		# 				
		# 				captcha_html=`cat $path_tmp/zdl2.tmp |grep "position:absolute;padding-left"`
		# 				unset post_data
		# 				unset ascii_dec
		# 				unset i
		# 				while [ ${#ascii_dec[*]} != 4 ];do
		# 					captcha_html="${captcha_html#*'position:absolute;padding-left:'}"
		# 					i="${captcha_html%%px*}"
		# 					captcha_html="${captcha_html#*'&#'}"
		# 					ascii_dec[$i]="${captcha_html%%';'*}"
		# 				done
		# 				pseudo_captcha
		# 				print_c 2 "Attendi:"
		# 				
		# 				code=${captcha[*]}
		# 				code=${code// /}
		# 				
		# 				s=65
		# 				while [ $s != 0 ]; do
		# 					echo -e "  \r\c"
		# 					echo -e $s"\r\c"
		# 					sleep 1
		# 					(( s-- ))
		# 				done
		# 				echo -e "  \r\c"
		# 				tmp="$path_tmp/zdl2.tmp"
		# 				input_hidden
		# 				post_data="${post_data//'op=catalogue&'}"
		# 				post_data="${post_data}&code=${code}"
		# 			fi
		# 			url_in_file="$url_in"
		
		# 		elif [ "$domain" != "${domain//shareflare.}" ]; then
		# 			
		# 			## http://www.shareflare.net ####
		# 			check_ip shareflare
		# 			get_tmps
		# 			tmp="$path_tmp/zdl.tmp"
		# 			input_hidden
		# 			if [ ! -f "${file_in}.st" ] && [ -f "${file_in}" ]; then
		# 					echo
		# 			else
		# 				wget --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&submit_ifree=Download file" http://shareflare.net/download4.php -O $path_tmp/download4.tmp &>/dev/null
		# 				echo -e "...\c"
		# 				unset post_data
		# 				
		# 				input_hidden
		# 				wget --load-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&frameset=Download file." http://shareflare.net/download3.php -O $path_tmp/download3.tmp &>/dev/null
		# 				echo -e "...\c"
		# 				
		# 				wget --load-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&frameset=Download file." "http://shareflare.net/tmpl/tmpl_frame_top.php?link=" -O $path_tmp/tmpl_frame_top.php &>/dev/null
		# 				echo -e "...\c"
		# 				
		# 				print_c 2 "Attendi circa 45 secondi:"
		# 				
		# 				k=`date +"%s"`
		# 				while [ "$goal" == "" ]; do
		# 					sleep 1
		# 					s=`date +"%s"`
		# 					s=$(( $s-$k ))
		# 					echo -e $s"\r\c"
		# 					
		# 					if (( $s>40 )); then
		# 						wget --load-cookies=$path_tmp/cookies.zdl --post-data=$post_data"&frameset=Download file." "http://shareflare.net/tmpl/tmpl_frame_top.php?link=" -O $path_tmp/tmpl_frame_top.php &>/dev/null
		# 						
		# 						goal=`less $path_tmp/tmpl_frame_top.php |grep direct_link_0` #grep "========================="`
		# 						sleep 1
		# 					fi
		# 					if (( $s>90 )); then
		# 						break
		# 					fi
		# 				done
		# 				
		# 				url_in_file=${goal#*\"}
		# 				url_in_file=${url_in_file//\"*/}
		# 				
		# 				
		# 				n=1
		# 			fi
		# 			
				elif [ "$domain" != "${domain//easybytez.}" ]; then
					url_in_file=`wget -t 1 -T $max_waiting -O - $url_in -q 2>/dev/null |grep 'You have requested'`
					url_in_file="${url_in_file##*'<font color="red">'}"
					url_in_file="${url_in_file%%'</font'*}"
					#url_in_file="${url_in_file// /}"
					file_in=${url_in_file##*\/}
					
					not_available=`wget -t 1 -T $max_waiting -q -O - $url_in_file |grep "File not available"`
					#check_in
					
					#logic: [ $? == 2 ] && [ ! -f $file_in ]
					if [ ! -z "${file_in}" ] && [ ! -f "${file_in}" ] && [ -z "$not_available" ]; then
						check_ip easybytez
						
						wget -q -t 1 -T $max_waiting --retry-connrefused --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl -O "$path_tmp/zdl.tmp" $url_in_file &>/dev/null
						echo -e "...\c"
						
						tmp="$path_tmp/zdl.tmp"
						input_hidden
					
						wget -t 1 -T $max_waiting -q --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl --post-data="${post_data}&method_free=Free Download" $url_in_file -O $path_tmp/zdl2.tmp &>/dev/null
						echo -e "...\c"
						exceeded=`cat $path_tmp/zdl2.tmp |grep "Upgrade your account to download bigger files"`
						unset post_data
						if [ -z "$not_available" ] && [ -z "$exceeded" ]; then
					
							tmp="$path_tmp/zdl2.tmp"
							input_hidden
			
							wget -t 1 -T $max_waiting -q --load-cookies=$path_tmp/cookies.zdl --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl --post-data="${post_data}&btn_download=Download File" $url_in_file -O $path_tmp/zdl3.tmp &>/dev/null
							echo -e "...\c"
							unset post_data
						
							print_c 2 "Attendi circa 60 secondi:"
							for s in `seq 0 60`; do
								echo -e $s"\r\c"
								sleep 1
							done
							echo -e "  \r\c"
							tmp="$path_tmp/zdl3.tmp"
							input_hidden
							
							
							url_in_file="$url_in_file"
							post_data="${post_data}&btn_download=Download File"
						fi
					fi
						
				elif [ "$domain" != "${domain//uploaded.}" ]; then
					unset alias
					url_in_file="${url_in%/}"
					
					wget -t 1 -T $max_waiting $url_in_file -q -O $path_tmp/test_page.tmp &>/dev/null
					test_exceeded=`cat $path_tmp/test_page.tmp |grep 'small style'`
					test_exceeded="${test_exceeded#*'>'}"
					test_exceeded="${test_exceeded%'<'*}"
					test_exceeded=`echo $test_exceeded |grep GB`
					if [ ! -z "$test_exceeded" ]; then
						test_exceeded=${test_exceeded%' '*}
						test_exceeded=${test_exceeded//,/.}
						test_exceeded=`echo "( $test_exceeded>1 )" |bc -l 2>/dev/null`
					fi
					#not_available=`cat $path_tmp/test_page.tmp |grep 'Page not found'`
					test_available=`wget -q -O - -t 1 -T $max_waiting $url_in_file |grep "</html"`
		
					if [ "$test_exceeded" == "1" ]; then
						exceeded=1
					elif [ -z "$test_available" ]; then
						not_available=true
					else
						if [ "${url_in_file##*/}" != "${url_in_file//*file\/}" ]; then
							file_in=${url_in_file##*/}
							url_in_file2=${url_in_file%/*}
							file_id=${url_in_file2##*/}
						else 
							wget -t 1 -T $max_waiting "$url_in_file" -O $path_tmp/zdl.tmp &>/dev/null
							file_id=${url_in_file##*/} 
							file_in=`cat $path_tmp/zdl.tmp |grep "id=\"filename\""`
							file_in="${file_in//<\/a*/}"
							file_in="${file_in##*>}"
							if [ "$file_in" != "${file_in//'&alias;'/}" ]; then
								file_in="${file_id}_${file_in//'&alias;'/.}.alias"
							fi
							
						fi
						check_in
						if [ ! -f "$file_in" ]; then
							check_ip uploaded
							wget -t 1 -T $max_waiting --keep-session-cookies --save-cookies=$path_tmp/cookies.zdl "$url_in_file" -O $path_tmp/zdl.tmp &>/dev/null
							echo -e "...\c"
							
							cooking=`cat $path_tmp/zdl.tmp |grep ref_user`
							cooking="${cooking//*\(\'/}"
							cooking=${cooking//"'"*/}
							
							echo "uploaded.to     FALSE   /       FALSE   0       ref     $cooking" >> $path_tmp/cookies.zdl
							
							wget -t 1 -T $max_waiting --load-cookies=$path_tmp/cookies.zdl "http://uploaded.to/io/ticket/captcha/$file_id" -O "$path_tmp/goal.tmp" &>/dev/null
							echo -e "...\c"
							
							url_in_file=`cat $path_tmp/goal.tmp`
							url_in_file=${url_in_file//*domain:\'/}
							url_in_file=${url_in_file//\'*}
						fi
					fi
					
				else
					[ "$domain" != "" ] && print_c 3 "$domain non supportato da $PROG"
					not_available=1
				fi
				
				file_in="${file_in// /_}"
				
				if [ "$domain" != "${domain//uploaded.}" ] || [ "$domain" != "${domain//easybytez.}" ];then # || [ "$domain" != "${domain//sharpfile.}" ]; then
					if [ "$downloader_in" == "Axel" ]; then
						dler=$downloader_in
						downloader_in=Wget
						ch_dler=1
						print_c 3 "Il server non permette l'uso di $dler: il download verrà effettuato con $downloader_in"
					fi
				fi
				
				#### CHECK $url_in & $file_in:
				sanitize
				test_in=$?
			fi
			
			#### DOWNLOAD ####
			if [ "$test_in" == "6" ]; then
				unset test_in
				download
				
				if [ "$domain" != "${domain//nowdownload}" ]; then
					count_down=$(( $max_waiting/2 ))
				else	
					count_down=$(( $max_waiting+5 ))
				fi
				
				print_c 2 "Attendi:"
				while [ "$count_down" != 0 ]; do
					echo -e "  \r\c"
					echo -e $count_down"\r\c"
					sleep 1
					(( count_down-- ))
				done
				echo -e "  \r\c"
				
				unset no_newip
				check_freespace
				check_alias				
			else
				sleep 1
			fi
			
			if [ ! -f "$path_tmp/${file_in}_stdout.tmp" ] && [ ! -z "${file_in}" ]; then
				links_loop - "$url_in"
			fi
			
			if [ -z $no_newip ]; then
				[ "$domain" != "${domain//mediafire.}" ] && newip[${#newip[*]}]=mediafire
				[ "$domain" != "${domain//uploaded.}" ] && newip[${#newip[*]}]=uploaded
		# 		[ "$domain" != "${domain//shareflare.}" ] && newip[${#newip[*]}]=shareflare
				[ "$domain" != "${domain//easybytez.}" ] && newip[${#newip[*]}]=easybytez
	# 			[ "$domain" != "${domain//sharpfile.}" ] && newip[${#newip[*]}]=sharpfile
			fi
			[ "$ch_dler" == "1" ] && downloader_in=$dler && unset ch_dler
			unset checked
			noproxy
			if [ $multi == 1 ]; then 
				check_stdout
				show_data_stdout
				checked=1
			fi
			while [ -z "$checked" ]; do #file_in
				check_stdout
				show_data_stdout
				
				check_pid $pid_in
				test_pid=$?
				
				links_loop "in" "$url_in"
				if [ $? == 5 ] && [ $test_pid != 1 ]; then checked=1 ; fi
			done
			
			unset checked
			unset post_data goal not_available exceeded
		done
	fi
	if [ -f "$path_tmp/links_loop.txt" ]; then
		file="$path_tmp/links_loop.txt"
		
	else
		unset file
		while true; do 
			check_stdout
			show_data_stdout
			#sleep 4
			if [ -f "$path_tmp/links_loop.txt" ]; then
				file="$path_tmp/links_loop.txt"
				break
			fi
			
			for pid in ${pids_alive[*]}; do
				check_pid $pid
				test_pids=$?
				[ "$test_pids" != "1" ] && break
			done
			[ "$test_pids" != "1" ] && break
		done
	fi
	unset test_pids
	for pid in ${pids_alive[*]}; do
		check_pid $pid
		test_pids=$?
		[ "$test_pids" != "1" ] && break
	done
	( ( [ ! -f "$path_tmp/links_loop.txt" ] && [ "$test_pids" != "1" ] ) || [ -z "${pids_alive[*]}" ] ) && break
	#sleep 5
done

separator "-"
print_c 1 "Tutti i link per il download sono stati processati."
separator "-"

#test_cleaning=`ls $path_tmp/*_stdout.tmp 2>/dev/null`
#[ "$test_cleaning" == "" ] && rm -r "$path_tmp"
rm -r "$path_tmp"

echo
echo
if [ -f "$file_log" ]; then
	print_c 3 "In questa directory è presente un file che contiene un elenco di operazioni di $PROG terminate senza successo."
	echo -e "Per leggerlo, digita:\n\n cat $file_log\n\n"
fi


exit
